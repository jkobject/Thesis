\babel@toc {english}{}\relax 
\babel@toc {french}{}\relax 
\contentsline {chapter}{Résumé}{i}{chapter*.1}%
\contentsline {chapter}{Abstract}{iii}{chapter*.2}%
\contentsline {chapter}{Remerciements}{vii}{chapter*.3}%
\contentsline {chapter}{Liste des figures}{xiii}{chapter*.5}%
\contentsline {chapter}{Liste des tableaux}{xv}{chapter*.6}%
\contentsline {chapter}{Liste des abréviations}{xvii}{chapter*.7}%
\contentsline {chapter}{Preamble}{1}{chapter*.8}%
\contentsline {section}{\numberline {0.1}My background for this thesis}{1}{section.0.1}%
\contentsline {section}{\numberline {0.2}Introduction}{2}{section.0.2}%
\contentsline {subsection}{\numberline {0.2.1}The promises of cellular biology}{2}{subsection.0.2.1}%
\contentsline {subsection}{\numberline {0.2.2}GRN and the cell}{3}{subsection.0.2.2}%
\contentsline {subsection}{\numberline {0.2.3}Single-cell genomics}{4}{subsection.0.2.3}%
\contentsline {subsection}{\numberline {0.2.4}Current single cell tasks}{6}{subsection.0.2.4}%
\contentsline {subsection}{\numberline {0.2.5}AIVC: the virtual cell model}{7}{subsection.0.2.5}%
\contentsline {subsection}{\numberline {0.2.6}AI and neural networks}{8}{subsection.0.2.6}%
\contentsline {subsection}{\numberline {0.2.7}Optimization and loss landscapes}{9}{subsection.0.2.7}%
\contentsline {subsection}{\numberline {0.2.8}LLMs \& Bio-Foundation models}{9}{subsection.0.2.8}%
\contentsline {subsection}{\numberline {0.2.9}Current single cell foundation models}{10}{subsection.0.2.9}%
\contentsline {chapter}{Thesis Objectives}{11}{chapter*.9}%
\contentsline {subsection}{\numberline {0.2.10}Personal Objectives during the thesis}{11}{subsection.0.2.10}%
\contentsline {subsection}{\numberline {0.2.11}Initial Ph.D. objectives}{12}{subsection.0.2.11}%
\contentsline {subsection}{\numberline {0.2.12}Revised objectives}{13}{subsection.0.2.12}%
\contentsline {section}{\numberline {0.3}Chapters overview \& main contributions}{13}{section.0.3}%
\contentsline {subsection}{\numberline {0.3.1}Other contributions}{14}{subsection.0.3.1}%
\contentsline {chapter}{\numberline {1}scPRINT: pre-training on 50 million cells allows robust gene network predictions}{17}{chapter.1}%
\contentsline {section}{\numberline {1.1}Summary}{17}{section.1.1}%
\contentsline {section}{\numberline {1.2}Introduction}{17}{section.1.2}%
\contentsline {section}{\numberline {1.3}Results}{19}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}scPRINT: a scRNAseq foundation model for gene network inference}{19}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}scPRINT recovers biological features in its gene networks}{21}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}scPRINT outperforms the state of the art on cell type-specific ground truths}{24}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}scPRINT is competitive on tasks orthogonal to GN inference}{26}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}scPRINT highlights the role of ion exchange and fibrosis in the ECM of Benign Prostatic Hyperplasia}{28}{subsection.1.3.5}%
\contentsline {section}{\numberline {1.4}Discussion}{30}{section.1.4}%
\contentsline {section}{\numberline {1.5}Methods}{32}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Architecture}{32}{subsection.1.5.1}%
\contentsline {subsubsection}{Expression encoder}{32}{subsection.1.5.1}%
\contentsline {subsubsection}{Model}{35}{subsection.1.5.1}%
\contentsline {subsubsection}{Expression decoder}{35}{subsection.1.5.1}%
\contentsline {subsubsection}{Class decoder}{36}{subsection.1.5.1}%
\contentsline {subsection}{\numberline {1.5.2}Ablation study}{37}{subsection.1.5.2}%
\contentsline {subsection}{\numberline {1.5.3}Pretraining}{37}{subsection.1.5.3}%
\contentsline {subsubsection}{Optimization method}{37}{subsection.1.5.3}%
\contentsline {subsubsection}{The classification task}{38}{subsection.1.5.3}%
\contentsline {subsubsection}{The denoising task}{39}{subsection.1.5.3}%
\contentsline {subsubsection}{The bottleneck learning task}{40}{subsection.1.5.3}%
\contentsline {subsection}{\numberline {1.5.4}scDataloader}{41}{subsection.1.5.4}%
\contentsline {subsection}{\numberline {1.5.5}Extracting meta-cell gene networks from attention matrices in scPRINT}{42}{subsection.1.5.5}%
\contentsline {subsection}{\numberline {1.5.6}Heads selection}{43}{subsection.1.5.6}%
\contentsline {subsection}{\numberline {1.5.7}Normalization and network interpretation }{43}{subsection.1.5.7}%
\contentsline {subsection}{\numberline {1.5.8}Simulated datasets, BoolODE and Sergio}{44}{subsection.1.5.8}%
\contentsline {subsection}{\numberline {1.5.9}BenGRN and gene network metrics}{44}{subsection.1.5.9}%
\contentsline {subsection}{\numberline {1.5.10}Other evaluation metrics}{45}{subsection.1.5.10}%
\contentsline {subsection}{\numberline {1.5.11}Denoising Benchmarks}{46}{subsection.1.5.11}%
\contentsline {subsection}{\numberline {1.5.12}Fine-tuning}{46}{subsection.1.5.12}%
\contentsline {subsection}{\numberline {1.5.13}State-of-the-art methods used in benchmarking}{46}{subsection.1.5.13}%
\contentsline {subsubsection}{Gene network inference with an ensemble of trees (GENIE3)}{47}{subsection.1.5.13}%
\contentsline {subsubsection}{DeepSEM}{47}{subsection.1.5.13}%
\contentsline {subsubsection}{Single-cell generative pretraining transformer (scGPT)}{47}{subsection.1.5.13}%
\contentsline {subsubsection}{Geneformer}{48}{subsection.1.5.13}%
\contentsline {subsubsection}{scFoundation}{48}{subsection.1.5.13}%
\contentsline {subsubsection}{Marker-based cell type prediction with CellTypist}{49}{subsection.1.5.13}%
\contentsline {subsubsection}{Classification benchmark and associated methods}{50}{subsection.1.5.13}%
\contentsline {subsection}{\numberline {1.5.14}Ground truth preparation}{50}{subsection.1.5.14}%
\contentsline {subsubsection}{McCalla et al.}{50}{subsection.1.5.14}%
\contentsline {subsubsection}{Omnipath}{50}{subsection.1.5.14}%
\contentsline {subsubsection}{Gene networks from genome-wide perturb-seq}{50}{subsection.1.5.14}%
\contentsline {subsection}{\numberline {1.5.15}Details on the Benign Prostatic Hyperplasia analysis}{51}{subsection.1.5.15}%
\contentsline {subsection}{\numberline {1.5.16}Negative Binomial to Poisson relationship}{51}{subsection.1.5.16}%
\contentsline {subsection}{\numberline {1.5.17}Data availability}{52}{subsection.1.5.17}%
\contentsline {subsection}{\numberline {1.5.18}Code availability}{52}{subsection.1.5.18}%
\contentsline {chapter}{\numberline {2}Xpressor: Towards foundation models that learn across biological scales}{61}{chapter.2}%
\contentsline {section}{\numberline {2.1}Summary}{61}{section.2.1}%
\contentsline {section}{\numberline {2.2}Introduction}{61}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Foundation models across scales}{62}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Architectural modifications: compressed representations}{64}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Training modifications: fine-tuning}{65}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Contributions}{65}{subsection.2.2.4}%
\contentsline {section}{\numberline {2.3}Xpressor}{66}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Background}{66}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Approach}{66}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Results}{67}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Multi-scale Fine-tuning}{68}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Background}{68}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Approach}{69}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Results}{69}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}proof that fine-tuning ESM2 with an adapter layer is at least sufficient to learn to add co-expression information}{71}{subsection.2.4.4}%
\contentsline {subsection}{\numberline {2.4.5}argument about the Tishby et al. bottleneck learning approach}{71}{subsection.2.4.5}%
\contentsline {subsection}{\numberline {2.4.6}FSQ and other contrastive losses on the cell embeddings}{72}{subsection.2.4.6}%
\contentsline {paragraph}{VQ-VAE.}{72}{subsection.2.4.6}%
\contentsline {paragraph}{FSQ-VAE.}{72}{subsection.2.4.6}%
\contentsline {paragraph}{Contrastive regularization across embedding dimensions.}{72}{subsection.2.4.6}%
\contentsline {paragraph}{Dimension-specific classifiers.}{73}{subsection.2.4.6}%
\contentsline {chapter}{\numberline {3}scPRINT-2}{77}{chapter.3}%
\contentsline {chapter}{\numberline {4}Discussion and perspectives}{79}{chapter.4}%
\contentsline {chapter}{Discussion and perspectives}{79}{chapter.4}%
\ttl@starttoc {chapters@1}
\contentsline {section}{\numberline {4.1}collecting data in the wild}{79}{section.4.1}%
\contentsline {section}{\numberline {4.2}multi modality \& perturbations}{80}{section.4.2}%
\contentsline {section}{\numberline {4.3}AIVC}{81}{section.4.3}%
\contentsline {chapter}{\numberline {5}Conclusion}{83}{chapter.5}%
\contentsline {chapter}{Bibliography}{85}{chapter*.21}%
\contentsfinish 
