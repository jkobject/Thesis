% Fix for URLs and long text going outside page margins
\sloppy % Allow more flexible line breaking
\emergencystretch=1em % Extra stretch for line breaking

\titleformat
{\chapter} % command
[display] % shape
{\bfseries\Huge} % format
{ } % label
{2ex} % sep
{
    %\vspace{1ex}
} % before-code
[ \vspace{0ex}
] % after-code

\raggedbottom % Allow flexible page heights to reduce underfull vbox warnings

\chapter[scPRINT-2: Towards the next-generation of cell foundation models and benchmarks]{\gls{scPRINT}-2: Towards the next-generation of cell foundation models and benchmarks}
\label{article3}

\section{Summary}

Cell biology has been booming with foundation models trained on large
single-cell \gls{RNA-seq} databases, but benchmarks and capabilities remain
unclear. We propose an additive benchmark across a gymnasium of tasks to
discover which features improve performance. From these findings, we
present \gls{scPRINT}-2, a single-cell Foundation Model pre-trained across 350
million cells and 16 organisms. Our contributions in pre-training tasks,
tokenization, and losses made \gls{scPRINT}-2 state-of-the-art in expression
denoising, cell embedding, and cell type prediction. Furthermore, with
our cell-level architecture, \gls{scPRINT}-2 becomes generative, as
demonstrated by our expression imputation and counterfactual reasoning
results. Finally, thanks to our pre-training database, we uncover
generalization to unseen modalities and organisms. These studies,
together with improved abilities in gene embeddings and gene network
inference, place \gls{scPRINT}-2 as a next-generation cell foundation model.

\section{Introduction}\label{introduction}

For the last few years, Single-Cell Foundation Models (\gls{scFM}s), also
known as Virtual Cell models, have provided early approaches to modeling
the cell using single-cell RNA-seq data as their primary
modality\citep{cuiScGPTBuildingFoundation2024,theodorisTransferLearningEnables2023,yangScBERTLargescalePretrained2022a,rosenUniversalCellEmbeddings2023}. The field has been booming with these
transformer-based machine learning models trained on large databases of
tens of millions of cells. The models themselves contain tens to
hundreds of millions of parameters and are trained on unsupervised (or
semi-supervised) tasks such as predicting masked gene expression or
denoising expression. They can then be used as is to examine their
learned representations or fine-tuned to transfer their knowledge across
a range of everyday tasks in that modality. Many examples have now been
proposed, such as predicting single-cell perturbation responses, patient
drug responses, and disease states; annotating cells; correcting for
batch effects; improving noise levels; imputing unseen gene expression
or modality; generating gene networks; identifying cell niches; and
more\citep{xiongScCLIPMultimodalSinglecell2023,zhaoLangCellLanguagecellPretraining2024,yangScBERTLargescalePretrained2022a,dedonnoPopulationlevelIntegrationSinglecell2023,yangGeneCompassDecipheringUniversal2023,baiScLongBillionParameter2024,zengCellFMLargescaleFoundation2025,tejadaLapuertaNicheformerFoundationModel2025,pearceTranscriptFormerCrossSpeciesGenerative2025,dingPrivacypreservingPredictiveFoundation2025,fuFoundationModelTranscription2025}.

While many AI Virtual Cell models and \gls{scFM}s exist, little has been done
regarding their comparison\citep{deeperEvaluationSinglecellFoundation2024,liuEvaluatingUtilitiesFoundation2024,reusabilityReportExploringSpatial2025,crowleyBenchmarkingCellTypeGene2025,delineatingEffectiveUseSelfSupervisedLearning2024}. A crucial question
remains: how to validate the impact of the different proposed methods,
regardless of implementation, datasets, or model size. Indeed,
reproducing results has been challenging for many, and the literature
has yielded discordant conclusions about the performance and
capabilities of these models. Showing they often underperform simpler
approaches on classification, batch correction, and perturbation
prediction\citep{deeperEvaluationSinglecellFoundation2024,liuEvaluatingUtilitiesFoundation2024,nourisaGeneRNIBLivingBenchmark2025,bendidiBenchmarkingTranscriptomicsFoundation2024,attiFullArticleFundamental2025}. Much work remains to get to
feature-rich, easy-to-use \gls{scFM}s. Models that allow inference in minutes,
along with well-crafted reproducible benchmarks that demonstrate how
\gls{scFM}s uniquely solve essential problems in single-cell biology.
Open-sourcing not just model weights but their pre-training tasks and
datasets.\textbf{\hfill\break
}

On this front, scPRINT was released as part of a second batch of scFM,
presenting contributions in terms of usability and reproducibility while
also showcasing pre-training strategies, data encoding, and
decoding\citep{scprint}. scPRINT was trained on 50 million cells
using a multitask pre-training strategy that included expression
denoising, autoencoding, and cell-label prediction. It also presented an
in-depth benchmark that examined the foundation model's zero-shot
performance on these tasks, as well as its internal gene network
representation and fidelity compared to multiple ground truths.

Building on these strengths and moving towards the next generation of
\gls{scFM}s, we here use scPRINT (which will be referred to as scPRINT-1) as
the reference to showcase an extensive additive benchmark of scFM
attributes. We address several key questions about the importance of
diverse architectures, datasets, and training modalities. This additive
benchmark aims to understand the relative importance of these different
features in our task gymnasium, examining the choice of model
architecture and pre-training tasks across 42 different scenarios. In
these scenarios, we propose a breadth of novel components for \gls{scFM}s. In
addition to those 12 distinct contributions, we also examine various
pre-training datasets, compiling a 350-million-cell database---the
largest to date---with over 16 organisms.

As a result of the benchmark, we derive a next-generation scFM,
	extbf{\gls{scPRINT}-2}. \gls{scPRINT}-2 improves upon the previous generation of
models by leveraging our database, the \gls{scPRINT}-2 corpus, and multiple
data augmentation approaches. It uses a set of updated pre-training
tasks and losses, improving its accuracy in challenging and unseen
contexts. Finally, it is equipped with graph-based encoders and the
XPressor architecture, enabling unprecedented expression imputation,
high-quality zero-shot embeddings, and counterfactual reasoning. We dive
into these specific contributions by examining multiple use cases,
highlighting behaviors that are often overlooked or under-assessed in
classical benchmarks.

\gls{scPRINT}-2, its dataloader, pre-training datasets, preprocessing, task
functions, pre-trained weights, as well as the additive benchmark
training traces and all 42 models'{} weights are fully
open-sourced and available under the GPL-v3 License.

\section{Results}\label{results}

\subsection{Decoding the impact of a foundation model's architecture
through an additive
benchmark}\label{decoding-the-impact-of-a-foundation-models-architecture-through-an-additive-benchmark}

Many \gls{scFM}s have been developed in single-cell genomics. They have mostly
been studied in isolation, using their own benchmarks. While most of
them maintained relatively similar architectures, the impact of each
design's decisions was never thoroughly assessed. For example, scPRINT-1
uses a denoising reconstruction task similar to scFoundation. Still,
scFoundation uses the mean-squared-error (\textbf{MSE}) for the
reconstruction loss, whereas scPRINT-1 uses the zero-inflated
negative-binomial loss (\textbf{\gls{ZINB}}) (see
\hyperref[zinbmse-loss]{Methods}). scGPT and Geneformer utilize
masking, but scGPT bins expression counts (\textbf{binning}), while
scPRINT-1 does denoising and employs a continuous embedding with a log
transform and a pseudocount of 1 (\textbf{logp1})\citep{cuiScGPTBuildingFoundation2024,theodorisTransferLearningEnables2023}.
Other models, like cellPLM, instead use a contrastive learning approach,
which encourages embeddings of perturbed and unperturbed cell profiles
to be more similar to each other than those of different cell
profiles. This method is also known as InfoNCE or
Contrastive Cell Embedding (\textbf{CCE}) (see
\hyperref[embedding-contrastive-loss]{Methods})\citep{oordRepresentationLearningContrastive2019}.

\subsubsection{Additive benchmark}\label{additive-benchmark}

To address the lack of a consistent assessment of these models, we have
designed a benchmark to comprehensively evaluate the various components
of \gls{scFM}s, including pre-training databases, architectures, and training
tasks. This benchmark is based on a gymnasium of tasks similar to those
presented in Kalfon et al.\citep{scprint} (see Figure \ref{fig:scprint2_overview}; see Table
\ref{tab:additive_benchmark}). The \gls{scFM} gymnasium assesses each model's ability to predict labels,
remove batch effects, denoise, and impute gene expression, as well as
discover known gene-gene relationships at different stages of training.
For embeddings and cell type classification, we use the \gls{scIB} and
accuracy scores over the same ground-truth test datasets as in Kalfon et
al. (see \hyperref[additive-benchmarks-datasets]{Methods}). For
denoising, we evaluate the model's ability to recover the noised
expression profile of cells from a test dataset, as measured by the
improvement in correlation with the ground-truth profile after
denoising. For gene-network inference, we examine the Odds Ratio (OR)
and \gls{AUPRC} scores of the model's ability to recover a ground-truth gene
network from expression data alone (see
\hyperref[gene-network-metrics]{Methods}).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/scprint2/image4.png}
    \caption[Presentation of the \gls{scPRINT}-2 model, pre-training dataset, and additive benchmark]{(a) The additive benchmark example table with its gymnasium scores across the \gls{scFM}'s features. (b) Our \gls{scPRINT}-2 corpus pre-training dataset, with 16 organisms across 300+ tissues. \gls{UMAP} of 15 million cells from the corpus integrated using \gls{scPRINT}-2. Colors represent species. (c) The \gls{scPRINT}-2 model, its input data, and its different outputs. Source data are provided as a Source Data file.}
    \label{fig:scprint2_overview}
\end{figure}

The base model, on which the additive benchmark is performed (see Figure
\ref{fig:scprint2_overview}, Table \ref{tab:additive_benchmark}, and \hyperref[base-model-and-training]{Methods}), is
trained on the CxG database, comprising 500 carefully annotated human
and mouse datasets. Its training lasts for a maximum of 20 epochs, each
of 20,000 steps, with a minibatch size of 64. We encode the gene
expression using the scPRINT-1 approach and decode it with the MSE
method. The base model's pre-training task uses a 30\% gene expression
mask. We pre-train the models 6 times across multiple seeds to generate
error bounds. Using Flash-Attention-3, the 20M parameters model trains
on 1 H100 \gls{GPU} for 2 days.

While we will not delve into the details of each feature assessed (see
\hyperref[additive-benchmark-1]{Methods}), our benchmark broadly
highlights several key points.

Regarding the tasks, we have confirmed what Kalfon et al. and De Waele
et al. previously showed: that denoising is superior to masking as a
pre-training task for single-cell data in classification and embedding
tasks\citep{scprint,deWaeleSystematicAssessment2025}. Similarly, un-normalized expression is
better than normalizing it at the input. Classification also serves as a
good supplement to the pre-training task, as without it, we observe a
slight decrease in performance (see Table \ref{tab:additive_benchmark}).

We also present, as part of our study, the \textbf{\gls{scPRINT}-2 corpus},
which comprises more than 350 million single cells (see Figure \ref{fig:scprint2_overview}). This
is the largest dataset ever assembled, consisting of data from the Chan
Zuckerberg Institute's Cellxgene (\textbf{CxG}), the \textbf{Tahoe}-100M
dataset, and the scBasecount database, which contains 20,000 reprocessed
datasets from the Gene Expression Omnibus\citep{programCZCELLxGENEDiscover2023,youngblutScBaseCount2025,zhangTahoe100M2025}. The
cells themselves are derived from 16 different eukaryotic organisms,
spanning more than 1 billion years of evolution. The dataset comprises
approximately 400,000 distinct genes, 4,764 different labels, and around
140,000 cell groups, totaling 25 TB of unique data\citep{jeremiekalfonTrainingFoundationModels}.
Our database contains nine main classes: \emph{cell type, disease, age,
tissue of origin, assay, ethnicity, sex, cell culture,} and
\emph{organism}.

Thanks to this database, we demonstrated the growing importance of data
selection in pre-training \gls{scFM}s. Indeed, when using the Tahoe-100M
database solely for pre-training, the model's overall performance
plummets, as the sequencing depth and diversity are low despite the
large number of cells.

However, including this lower-diversity dataset with the high-diversity
CxG database and carefully considering the cell-state imbalances results
in only a noticeable decrease in denoising performance. Interestingly,
using all available datasets did not change performance across our
benchmarks. Reducing the training database to a random subset of only
\textbf{200 human datasets only,} led to a minimal decrease in denoising
and cell type prediction. This shows again that the benchmark fails to
highlight abilities on more diverse cell types and
organisms\citep{maloneModelingSampleVariables2010,wolfSCANPYLargescaleSinglecell2018}. But it also indicates diminishing
returns in adding more datasets---diversity in cell states and organisms
being much more important than cell count.

We thus preprocessed each dataset by removing all duplicates, filtering
for low-quality cells, aligning metadata to the CxG ontologies, and
computing cell-cell similarity profiles and clusters. It allowed us to
introduce multiple data augmentation techniques, such as varying the
input context length (\textbf{var. context}) during training and
randomly creating \textbf{meta-cells}, which are averages of similar
cell expression profiles across K-nearest neighbors (K-NN) (see
\hyperref[a-multi-cell-denoising-auto-encoder-task-unlocks-new-modalities-and-performances]{Results
section 3}). Interestingly, we observe that both methods tend to
improve the model's performance in most metrics, even though these
models do not examine more cells overall. This highlights the importance
of effective data augmentation techniques for scFM
pre-training\citep{comprehensiveSurveyDataAugmentation2024}.

\begin{table}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/scprint2/image6.png}
    \caption[Full results of the additive benchmark]{Table representing the results of the additive benchmark on 42 models, over multiple metrics: batch correction and cell embedding quality, denoising quality, cell type prediction, and gene network inference. Additional information on the different components is available in the methods section. Bold elements are the features that are part of the \gls{scPRINT}-2 foundation model.}
    \label{tab:additive_benchmark}
\end{table}

Regarding architecture, we recomputed results from the XPressor
manuscript\citep{kalfonTowardsFoundationModels2025}, which showed that this architecture
improves the embedding quality of \gls{scFM}s (see
\hyperref[an-efficient-hierarchical-attention-architecture-makes-scprint-2-generative]{Results
section 4}; see the full table in Supplementary Table~\ref{table-s1-detailed-version-of-the-additive-benchmark}). We also demonstrate
that using ESM-based gene ID tokens leads to much better performance
than learning gene tokens from scratch\citep{linLanguageModelsProtein2022}. Providing
each gene's genomic location as additional input information
significantly improves model convergence. However, we also noticed that
when they do converge, models without gene location information can
perform well. We have noticed that model size correlates with higher
scores, at least for gene network inference and cell-type prediction.
Using a Graph Neural Network (\textbf{GNN}) encoder shows significant
improvements, with only a slight decrease in the cell-type prediction
task (see Results Section 3; see \hyperref[methods]{Methods}).
Additionally, our sub-quadratic attention mechanism, Criss-cross
attention, also shows substantial benefits with no reduction in
performance (see Results section 4; see \hyperref[methods]{Methods}).

Moreover, \gls{MSE}, on average, outperforms \gls{ZINB} as a loss function while
decreasing the model's expressivity (see
\hyperref[base-model-and-training]{Methods}). A good proposed
middle ground is the \gls{ZINB}+\gls{MSE} loss (see
\hyperref[a-multi-cell-denoising-auto-encoder-task-unlocks-new-modalities-and-performances]{Results
Section 3}; see \hyperref[zinbmse-loss]{Methods}).

Some unexpected results showed that omitting the decoder part of
scPRINT-1 led to stronger performance; however, this comes at the cost
of generative abilities and decreased cell-embedding fidelity. Indeed,
despite its importance for understanding \gls{scFM}s' behavior and feature
importance, we have noted that our benchmark does not yet capture the
full breadth of abilities that \gls{scFM}s do or should have. For example,
both \gls{scIB} and classification scores are very dependent on the
dataset' s quality and its labels. Scores presented here
show only a facet of the model's ability. We might be interested in the
model's performance up-to-convergence instead of stopping them at 20
epochs or looking at unseen species, or assays at training. This is a
first attempt to benchmark \gls{scFM}s, but more extensive efforts will be
needed.

\subsubsection{\gls{scPRINT}-2}\label{scprint-2}

Overall, we have examined the performance improvements driven by our 12
distinct contributions across 42 training runs. Based on these results
and our own considerations, we have elected a set of features to create
\gls{scPRINT}-2, a next-generation cell foundation model (see Supplementary Figure~\ref{fig-s1-illustration-of-the-full-scprint-2s-architecture-input-and-output};
see \hyperref[scprint-2-1]{Methods}). We highlight its architecture
in Figure \ref{fig:scprint2_overview}; \gls{scPRINT}-2 is currently available in a small version with
only 20M active parameters. Its encoder-compressor-decoder architecture
produces cell- and gene-level outputs at multiple levels, working on one
or more cells at a time.

Furthermore, to aid in the exploration of this largest-ever
cross-organism single-cell dataset, we release all of the 350 million
cells in the \gls{scPRINT}-2 corpus, aligned into an atlas by \gls{scPRINT}-2, of
which 1\% are directly accessible through an interactive visualization
(see Figure \ref{fig:scprint2_overview}, see \hyperref[data-availability]{Data
availability}) along with \gls{scPRINT}-2 cell label predictions for all
classes. This should enable never-before analysis and exploration of
single-cell RNA-seq data.

But the additive benchmark leaves some questions unanswered about the
effect of combining these features up-to-convergence and the models'
abilities on unseen modalities, tasks, and species. In the following
sections, we will focus on 1. looking at more diverse and truthful
datasets in size, quality, and source domains; 2. using more scores and
ground truth validations; 3. defining tasks that better reflect the
possibilities and real-life use of these models.

\subsection{A diverse dataset of 350 million cells pushes generalization
to unseen
organisms}\label{a-diverse-dataset-of-350-million-cells-pushes-generalization-to-unseen-organisms}

One of the most critical features of foundation models (FMs) is the
breadth of their training dataset. From vision to language, AI
advancement has been driven by training models on ever-larger
datasets\citep{brixiGenomeModelingDesign2025,openaiGPT4TechnicalReport2024,kaplanScalingLawsNeural2020,oquabDINOv2LearningRobust2024,chenUNIGeneralpurposeFoundation2024}. Nowadays, most \gls{scFM}s are trained on 20
to 50 million cells, except the recently released Geneformer-v2 and
STATE-SE models, which have been trained on roughly 300 million
cells\citep{chenQuantizedMultitaskLearning2024,predictingCellularResponsesPerturbation2025}.

\subsubsection{scPRINT-2 pre-training
corpus}\label{scprint-2-pre-training-corpus}

In conjunction with our model's architecture, the \gls{scPRINT}-2 corpus and
its 16 organisms enable generalization to organisms unseen during
training. This broader cell type diversity, however, comes with
additional challenges: annotation quality has decreased due to missing
annotations in scBasecount. Additionally, the skew toward low sequencing
depth and highly similar cells has increased with the inclusion of
spatial transcriptomics datasets and less curated databases such as
Tahoe-100M and Arc's scBasecount (see
\hyperref[depth-weighted-sampling]{Methods}).

Fortunately, a key feature of our dataloader,
scDataLoader\citep{scprint}, is its ability to perform weighted
random sampling, thereby mitigating the heavy dataset imbalances that
currently exist across diverse cell types, sequencing methodologies, and
different organisms assessed. We thus present methods to successfully
train \gls{scPRINT}-2 on this large dataset. The first, called
cluster-weighted sampling, allows datasets with unclear annotations to
benefit from weighted random sampling by defining clusters of high
expression similarity (see
\hyperref[cluster-weighted-sampling]{Methods}). This lets us define
cell states without requiring any label information and perform sampling
that is aware of the different cell states, regardless of the size of
each cluster. We address the second issue of uneven cell quality by also
skewing sampling toward cells with more non-zero genes (\gls{NNZ}). Both
methods were enabled on such a vast database thanks to essential updates
to scDataLoader. This re-weighting is performed jointly with weights on
cell type, disease, organism, and sequencer labels, thereby addressing
the size/diversity issues that plague these larger cell
databases\citep{alsabbaghFoundationModelsMeet2023}.

Interestingly, the number of training steps required to achieve
convergence increased only 2-fold, indicating that, as in \gls{scPRINT}-1, the
model did not sample as many cells as actually exist in the pre-training
dataset before reaching convergence. However, with data augmentation and
nearest-neighbor sampling, the model still encountered roughly 2 billion
distinct input cell profiles during pre-training, corresponding to 2000
cell profiles per step.

After implementing this feature and training \gls{scPRINT}-2, its cell-type
classification performance on the validation dataset was 76\%. For its
other predicted labels, its performance was 59\% (disease), 96\%
(ethnicity), 96\% (assay), 94\% (age), 100\% (cell culture), 100\%
(organism), 93\% (sex), and 70\% (tissue of origin).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/scprint2/image2.png}
    \caption[Presentation of the updated classifier and results on classification tasks]{(a) Open Problems benchmark results and comparison of scPRINT-1 and zero-shot and fine-tuned \gls{scPRINT}-2. (b) Illustration of our updated hierarchical classifier loss. (c) Unseen organisms cell type classification for cat and tiger datasets, across two experts and \gls{scPRINT}-2 zero-shot, after label smoothing, after cluster aggregation, and after fine-tuning. (d) Change in classification accuracy as the number of genes in context increases for high-quality single-cell datasets. The star represents the model's score when label smoothing is used.}
    \label{fig:scprint2_classifier}
\end{figure}

On the live benchmark Open Problem from November 2025, it achieved an
average zero-shot performance of 75\%, putting it above \gls{scPRINT}-1 (47\%)
and other zero-shot FMs (40-60\%), even above Liger, a supervised
technique\citep{lueckenDefiningBenchmarkingOpen2025} (see Figure \ref{fig:scprint2_classifier}; see
\hyperref[open-problem-benchmarks]{Methods}). But \gls{scPRINT}-2 was the
only \gls{scFM} with UCE that could run on all datasets\citep{rosenUniversalCellEmbeddings2023}.
Against the two human datasets on which Scimilarity-KNN could be run, it
performed slightly better than \gls{scPRINT}-2. This is most likely due to the
smaller capacity of \gls{scPRINT}-2 (20M parameters) compared to scimilarity
(100M parameters), as we also observed in our additive benchmark (see
Table \ref{tab:additive_benchmark}). Another likely reason is that the model likely saw those
datasets more often during pre-training, since it is trained only on
CxG's human datasets.

We then performed fine-tuning using our XPressor-based
Parameter-Efficient Fine-tuning (\gls{XPEFT}), in which we fine-tune only the
XPressor layers of \gls{scPRINT}-2 (see
\hyperref[fine-tuning-task]{Methods}). In this context, we show
that \gls{scPRINT}-2 fine-tuned outperforms every existing supervised and
unsupervised method on the Open-problem (see Results section 4; see
\hyperref[xpressor-model]{Methods})\citep{xuParameterEfficientFineTuning2023}. We
observed similar trends in the macro-F1 scores (see Supplementary Figure~\ref{fig-s2-barplot-of-the-f1-macro-scores-on-the-label-projection-task-of-the-open-problem-benchmark}). Of
note, neither \gls{scGPT} nor Geneformer are currently tested in their
fine-tuned version on the platform.

These performances are enabled in part by our update to scPRINT-1's
hierarchical classification loss (see Figure \ref{fig:scprint2_classifier}). The scPRINT-1
classifier generates predictions for all possible labels in a
hierarchical ontology, while producing logits only for the leaf labels.
To predict the other labels, it only has to aggregate their leaf logits.
In \gls{scPRINT}-2, we improve on this loss by using the entire ontological
graph, meaning that, e.g., given a ground truth of \emph{olfactory
neuron,} we will penalize a prediction of \emph{inhibitory neuron} less
overall than a non-neuron label, like \emph{fibroblast}. In conjunction
with our weighted sampler, this allows the model to learn rich gradients
from a low volume of data.

\subsubsection{\gls{scPRINT}-2 generalizes to unseen classification
tasks}\label{scprint-2-generalizes-to-unseen-classification-tasks}

We have, however, noticed that classification performance does not
generalize sufficiently to correctly recover the exact phylogenetic
relationships within organisms or, similarly, within ethnicities (see
Supplementary Figures~\ref{fig-s3-heatmap-of-ethnicity-prediction-relationship-across-samples}, \ref{fig-s4-heatmap-of-organism-prediction-relationship-across-samples}, \ref{fig-s5-heatmap-of-organism-prediction-relationship-using-organism-embedding-similarity-across-samples}). This could be biased heavily by tissue
representation in rare ethnicities and organisms. However, some
relationships were found, such as \emph{Singaporean Indian/Singaporean
Chinese, Korean/Japanese/Chinese, American/Latin American,} or
\emph{Macaque/Marmoset/Chimpanzee, Drosophila/C. elegans, Human/Mouse,
Pig/Cow}, suggesting that with greater diversity and representation,
\gls{scFM}s might learn this relationship classification of gene expression on
their own.

We show that this does not prevent \gls{scPRINT}-2 from generalizing to unseen
organisms. Using a randomly selected tomato plant dataset and its
corresponding ESM3 gene embeddings, unseen at training time, \gls{scPRINT}-2
generates an organism label prediction for the two plant organisms it
knows about 67\% of the time. This is despite the very low prevalence of
these organisms in the pre-training dataset (see Figure \ref{fig:scprint2_overview}). For a horse
dataset, \gls{scPRINT}-2 predicted mammalian organisms 72\% of the time.

Unfortunately, these datasets lacked cell-type annotations. Using
well-annotated datasets from Zhong et al.\citep{zhongBenchmarkingCrossspeciesSinglecell2025} of cat and
tiger lung tissues, organisms not seen at training time, we generate
cell type predictions using \gls{scPRINT}-2 and achieved a prediction accuracy
of 42.2\% across the 500 potential cell type leaf labels \gls{scPRINT}-2 knows
about. While this score may seem low compared to supervised approaches,
it is worth noting that labels from a secondary source were available in
the datasets. Comparing them to the initial ground truth, we found only
a 55.3\% agreement between the two. Furthermore, we noticed that for
some cells, annotations were quite different, such as: \emph{fibroblast}
being labelled as \emph{ciliated cell}, \emph{macrophage} as
\emph{neuroendocrine cell, and} \emph{ionocyte} as \emph{secretory
cell}.

Given the low correspondence between the two expert annotations, we
wanted to determine which was correct between \gls{scPRINT}-2 zero-shot or the
expert ground-truth labels. We conducted a differential expression
analysis between cells labeled as \emph{type 2 pneumocyte} by \gls{scPRINT}-2
(zero-shot) but as \emph{macrophage} by the ground truth (see Supplementary
Figure~\ref{fig-s6-differential-expression-plots-of-the-disagreeing-cells-between-scprint-2-and-ground-truth}). We saw that the most highly differentially expressed genes
were \emph{MAGI1}, \emph{NPNT}, \emph{TEAD1}, and \emph{LMO7}, which are
involved in cell-cell junctions, epithelial cells, alveolar cells, and
lung tissues. Moreover, the first differentially expressed gene was
\emph{SFTPC}, a known ``type 2 pneumocyte'' marker. This means that,
even in this challenging unseen-organism dataset, \gls{scPRINT}-2 seems to
legitimately correct expert annotations. This showcases strong
generalization to unseen organisms.

To further improve \gls{scPRINT}-2's accuracy, we use a method first presented
in Hu et al. to aggregate predictions based on \textbf{nearest neighbor
smoothing} of the model's class logits (see
\hyperref[logits-refinement-laplacian-smoothing]{Methods})\citep{herrmannLaplacianIsoparametricGrid1976,huGRITGraphRegularized2025}.
This approach increased accuracy in most of our use cases but yielded a
small 1.3\% improvement here. We also provide tools to perform
\textbf{top-K predictions} and \textbf{confidence-based selection}. This
means that \gls{scPRINT}-2 can list multiple putative labels for each cell.
When multiple labels have high logits, it can output their shared
parental label for that cell instead. When labels disagree, or the
logits are low, \gls{scPRINT}-2 can output an ``unknown'' label instead. Using
both approaches together, we get an additional 3\% improvement in
accuracy, with 10\% of the cells now listed as ``unknown''.

Additionally, the low accuracy is also related to \gls{scPRINT}-2 predictions
being cell-specific, whereas most ground truth labels are
cluster-specific. We propose a \textbf{cluster-based logits averaging,}
which can be viewed as an extreme case of smoothing (see
\hyperref[cluster-aggregation]{Methods}). With this tool, \gls{scPRINT}-2
performance increased by 12\% (see Figure \ref{fig:scprint2_classifier}). Beyond improved accuracy,
these inference-time contributions significantly enhance the usefulness
of scFM-based cell annotation for biologists.

Finally, we also demonstrate that with our XPEFT method (presented
further in
\hyperref[an-efficient-hierarchical-attention-architecture-makes-scprint-2-generative]{Results
section 4}), \gls{scPRINT}-2 can improve its predictions to 95\% accuracy in
the test subset, while preserving some fine-grained cell-type
distinctions not present in the training data (see Figure \ref{fig:scprint2_classifier}).

We then assessed \gls{scPRINT}-2' s performance as we increased
the number of genes in context. We used a Smart-seq-v4 dataset from
Jorstad et al., averaging around 6000 \gls{NNZ} genes per cell (see Supplementary
Figure~\ref{fig-s7-umap-of-the-smart-seq-dataset-used-in-the-varying-context-classification-task})\citep{jorstadTranscriptomicCytoarchitectureReveals2023}. As shown in Figure \ref{fig:scprint2_classifier}, we observed an
overall increase in prediction accuracy across all labels as we
increased the context from 200 to 8000 genes, even though \gls{scPRINT}-2 was
pre-trained on only 3200 genes, demonstrating generalization to larger
input contexts. Interestingly, classes such as sex and ethnicity reached
much better predictive accuracy as we increased the number of genes.
When using only the most expressed genes in context, we observed that
cell types, which are often defined by highly expressed canonical genes,
remained relatively high, even with only 200 genes in context (see Supplementary
Figure~\ref{fig-s8-line-plot-of-the-classification-across-varying-context-length-using-the-most-expressed-genes}).

Training \gls{scFM}s on large dataset sizes does not necessarily improve the
model's performance. It is the breadth of cell types, conditions,
organisms, and cell quality that produces real generalization abilities.
We showcased it here, with scPRINT2 able to label unseen organisms,
improving its predictions across various context lengths and rare
modalities. We also showed \gls{scPRINT}-2 reaching state-of-the-art
classification accuracy with our fine-tuning.

We will now see how some of our contributions in training loss and data
augmentation can similarly improve performance in denoising and
imputation in unseen modalities.

\subsection{A multi-cell denoising auto-encoder task unlocks new
modalities and
performances}\label{a-multi-cell-denoising-auto-encoder-task-unlocks-new-modalities-and-performances}

Not all single-cell datasets are at the sequencing depth and quality of
Smart-seq-v4. On average, single-cell data has very low depth,
preventing \gls{scFM}s from learning features that may only be seen in
higher-quality cellular profiles.

\subsubsection{Meta-cells and graph neural network
encoder}\label{meta-cells-and-graph-neural-network-encoder}

In addition to biasing sampling toward cells with more non-zero genes
(\gls{NNZ}), \gls{scPRINT}-2's dataloader now uses neighborhood information, whether
defined in expression space or via spatial transcriptomics (see Figure
\ref{fig:scprint2_denoising}; see \hyperref[multi-cell-sampling]{Methods}). This allows users
to create models that take into account nearest neighbor cells during
pre-training. This can be done, for example, by creating
\textbf{meta-cells}. Meta-cells average the expression over the cell and
its neighbors to artificially create a higher-depth cell with less
dropout. We demonstrate that this approach achieves improved results
across multiple model metrics, but not in denoising (see Table \ref{tab:additive_benchmark}). While
17\% of cells in the dataset have more than 2600 non-zero values, 11\%
had at least 3200. With \gls{NNZ}-weighted sampling, we reach 33\%. By adding
metacells, half of our input expression profiles now have more than 3200
\gls{NNZ} elements---allowing us to extend \gls{scPRINT}-2's context to 3200 genes.

However, one can go beyond meta-cells and, instead of averaging, use a
graph neural network (\textbf{GNN}) (see Figure \ref{fig:scprint2_denoising}; see
\hyperref[gnn-expression-encoder]{Methods})\citep{zaheerDeepSets2018,corsoGraphNeuralNetworks2024}.
In this case, the set of neighbors' expressions is encoded in the input
token of the transformer. We show that this improves the model's
denoising ability. However, we also noticed a decrease in cell embedding
and classification (see Table \ref{tab:additive_benchmark}). Further experiments showed that this
was mitigated with longer training time. As in the variable context
case, we variably select 0 to 6 neighbors per minibatch, so the model
learns to use a variable number of cell neighbors (see Supplementary Figure~\ref{fig-s9-illustration-of-the-multiple-perturbations-applied-to-expression-data-in-scprint-2},
see \hyperref[multi-cell-sampling]{Methods} for details on the
choice of neighbors).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/scprint2/image5.png}
    \caption[Presentation of the expression encoder and decoders and performance on denoising and imputation tasks]{(a) Overview of \gls{scPRINT}-2's multi-cell expression encoder and (b) \gls{scPRINT}-2's expression decoder loss. Circles represent scalar values, orange blocks represent vectors. (c) Benchmark of \gls{scPRINT}-2 on expression denoising over nine datasets of varying quality, compared to MAGIC and scPRINT-1. (d) \gls{UMAP} of the Xenium's patches of cells' expression pre/post denoising with \gls{scPRINT}-2. (e) Expression denoising of IRF8 with \gls{scPRINT}-2 over a sub-patch of the Xenium melanoma dataset with cell contour overlaid. (f) Overview of the patch selection in the Xenium dataset, and of the mapping and pseudo-imputation with Tangram using a matched melanoma 10x v3 \gls{scRNA-seq} dataset. (g) Correlation-based denoising \& imputation scores of \gls{scPRINT}-2 and denoising of MAGIC on the matched dataset. (h) \gls{scPRINT}-2 cell type prediction over the Xenium melanoma patch. (i) Expression-based clusters and \gls{scPRINT}-2 disease prediction of cells from the Xenium melanoma patch analyzed. Source data are provided as a Source Data file.}
    \label{fig:scprint2_denoising}
\end{figure}

Pushing our analysis further, we realized that a mix of both scores,
which we call \textbf{\gls{ZINB}+MSE} (see Figure \ref{fig:scprint2_denoising}; see
\hyperref[zinbmse-loss]{Methods}), yields a better denoising score
while retaining the ability to model zero inflation and uncertainty (see
Table \ref{tab:additive_benchmark}). Together, these updates have already made \gls{scPRINT}-2 better
than scPRINT-1 and even better than MAGIC on our denoising benchmarks
(see Table \ref{tab:additive_benchmark}, see Figure \ref{fig:scprint2_denoising})\citep{dijkRecoveringGeneInteractions2018}. While these results
are already state-of-the-art, we wanted to explore the effects of
denoising and how to assess our model in unseen contexts.

Looking at denoising scores across technologies, we notice that
scPRINT-1 tends to perform much better on datasets with higher \gls{NNZ}
genes, i.e., higher-quality datasets (see Figure \ref{fig:scprint2_denoising}, see
\hyperref[denoising-task]{Methods}). However, within each dataset,
scPRINT-1 struggles more with low-depth cells than MAGIC \& \gls{scPRINT}-2,
which is more consistent overall. We explain this paradox by the fact
that, beyond \gls{NNZ} genes, the high-quality dataset often exhibits lower
biases in the distribution of \gls{NNZ} genes per cell (see Supplementary Figure~\ref{fig-s10-distplot-of-the-non-zero-count-distribution-across-cells-from-the-three-dataset-qualities-used}).
This also explains why MAGIC and \gls{scPRINT}-2 perform better than scPRINT-1
in these biased datasets. Indeed, they can look at the neighbor's
expression and model the expression biases this way. This usage explains
the significant improvements in the low- and mid-quality datasets,
making \gls{scPRINT}-2 state-of-the-art across all tested contexts and
modalities using its estimate of zero-inflation.

\subsubsection{scPRINT-2 generalizes to unseen denoising
tasks}\label{scprint-2-generalizes-to-unseen-denoising-tasks}

Additionally, we decided to look at performance on a Xenium dataset, a
modality completely absent from \gls{scPRINT}-2's training (see
\hyperref[xenium-analysis]{Methods})\citep{10xgenomicsXeniumPrimeFFPE2024}. We
elected to use a large, recent skin melanoma dataset with a 5000-gene
panel, reaching the upper limit of what is doable with current
technology.

A first proof of \gls{scPRINT}-2's denoising is the \gls{scIB} biological
truthfulness of the Xenium dataset, which improves over the raw
expression embedding when using its embeddings (see Figure \ref{fig:scprint2_denoising}; see
Supplementary Figure~\ref{fig-s11-umap-over-scprint-2-and-pca-embeddings-of-the-xenium-dataset}; see Supplementary Table~\ref{table-s3-detailed-scib-biological-conservation-scores-on-the-xenium-dataset}). To further assess how well
\gls{scPRINT}-2 can denoise this unseen data modality, we leverage the optimal
transport-based method Tangram\citep{biancalaniDeepLearningAlignment2021}. We used Tangram to
map each Xenium cell to another cell in a non-spatial 10X v3 dataset of
similar skin melanoma\citep{zhangSinglecellAnalysisReveals2022} (see Figure \ref{fig:scprint2_denoising}). Here, the
mapping quality is low due to many differences between the two
technologies, e.g., number of cells, number of genes per cell, or biases
in cell and gene types (see Supplementary Figure~\ref{fig-s12-tangram-mapping-quality-plots}). Still, using the 10X v3
dataset as ground truth, we can see that MAGIC and \gls{scPRINT}-2 recreate an
expression profile that correlates more than 30\% better with the 10X
dataset than does Xenium (see Figure \ref{fig:scprint2_denoising}). There, MAGIC creates
expression profiles closer to the 10X ones, while \gls{scPRINT}-2 remains
closer to the initial Xenium profiles, and both \gls{scPRINT}-2 and MAGIC tend
to agree more with each other than with anything else (see Figure \ref{fig:scprint2_denoising}).

Overall, this suggests that using a tool like \gls{scPRINT}-2 might be a
better alternative for denoising and imputing expression from Xenium
than using a secondary non-spatial 10X dataset and aligning it with
Tangram.

At the same time, MAGIC can only perform denoising and cannot impute
expression for unseen genes. We thus use \gls{scPRINT}-2 to impute a random
subset of 5000 genes present only in the 10X v3 dataset. Interestingly,
we noticed that feeding all 5000 (expressed in Xenium) + 5000
(unexpressed in Xenium) genes in context did not lead to good
imputation. However, using \gls{scPRINT}-2's generative architecture, we
directly decoded the 5000 10X-only genes from the \gls{scPRINT}-2's cell
tokens generated on the 5000 Xenium genes (see Supplementary Figure~\ref{fig-s13-illustration-of-scprint-2s-generative-imputation-mechanism}). We
show that this imputation scores as high as the denoised Xenium genes
(see Figure \ref{fig:scprint2_denoising}).

Finally, we also wanted to examine \gls{scPRINT}-2's cell-label predictions on
this unseen modality. While we did not have access to ground-truth
labels in this dataset, we could already spot-check the validity of the
predictions. Indeed, many cell types were labeled as \emph{basal} or
\emph{epidermis}, with numerous immune cell labels in the cancer-induced
lesion in the tissue (see Figure \ref{fig:scprint2_denoising}). This entire lesion region was
labeled as \emph{cancer} by \gls{scPRINT}-2. This was striking as it contained
mostly non-cancerous activated immune cells (see Figure \ref{fig:scprint2_denoising}; see Supplementary
Figure~\ref{fig-s14-spatial-plot-of-the-xenium-melanoma-dataset-with-scprint-2-predicted-cell-labels}). It likely reflects the biases of the pre-training dataset,
where disease labels are often applied at the dataset level rather than
the cell level, making \gls{scPRINT}-2's disease predictions sometimes
imprecise. Thankfully, many cells had the cell-type label
`\emph{malignant cell}'. These cells were distributed throughout the
tissue and showed a strong signal for the five key literature melanoma
genes (\emph{BCL2, IGF1, EGFR, FGFR2, SOX10}) (see Supplementary Figures~\ref{fig-s15-violin-plot-comparison-of-the-genes-expression-between-predicted-malignant-vs-the-rest} and~\ref{fig-s16-differential-expression-plot-of-cancer-disease-labelled-vs-rest-in-the-xenium-dataset}).

Overall, we have seen how \gls{scPRINT}-2 can be used on challenging
modalities to augment a given dataset with cell label predictions,
expression denoising, and gene imputation. Showing yet again another
axis of generalization. We will now focus on how some of our contributions in training loss and data
augmentation can similarly improve performance in denoising and
imputation in unseen modalities.

\subsection{An efficient, hierarchical attention architecture makes
scPRINT-2
generative}\label{an-efficient-hierarchical-attention-architecture-makes-scprint-2-generative}

\subsubsection{Efficient attention architectures and compression
methods}\label{efficient-attention-architectures-and-compression-methods}

Implementing transformer models on new modalities is a potent way to
rethink some of their mechanisms. A common issue with transformer models
is their memory and compute requirements, which grow quadratically with
their context length (e.g., the number of genes in their input). This is
even more pronounced in bidirectional transformers like most \gls{scFM}s. With
the introduction of scPRINT-1, we presented a model that could train in
3 days on a regular A40 \gls{GPU} and on 50M cells, an order of magnitude
faster than most similar \gls{scFM}s. A first contribution to the \gls{scPRINT}-2
architecture is the addition of state-of-the-art approaches to reduce
the memory footprint and increase training speed. We modified the
attention mechanism in multiple ways, using grouped-query attention
(GQA) to reduce memory usage. We benchmarked additional attention
mechanisms alongside Flash-Attention-3 to assess their performance and
their speed.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/scprint2/image1.png}
    \caption[Presentation of the XPressor architecture and performance on cell embedding tasks]{(a) Presentation of the XPressor with \gls{VAE}-based compression. (b) Schematic representation of going from expression to classification with \gls{scPRINT}-2, XPressor, and \gls{VAE}-based compression. (c) Open-Problem scores for \gls{scPRINT}-2 across all methods. (d) \gls{UMAP}s of, respectively, \gls{PCA} embeddings, \gls{scPRINT}-2 zero-shot cell-type embeddings, and \gls{scPRINT}-2 fine-tuned cell-type embedding colors by known cell types and batches, with \gls{scIB} total scores. (e) Schematic representation of the counterfactual generation using \gls{scPRINT}-2's embedding and replacing them for the organism class from mouse to human. (f) Illustration of the decrease in distance between initially unrelated datasets from applying this counterfactual approach. (g) Differentially expressed genes post vs pre mouse ``humanization'' with \gls{scPRINT}-2. (h) Over-representation plot of the top positively differentially expressed genes in both human-like mouse and real human vs. mouse; the red line indicates random chance. Source data are provided as a Source Data file.}
    \label{fig:scprint2_xpressor}
\end{figure}

A first one is flash-\textbf{hyper attention}, which computes specific
attention only on sets of keys and queries known to be similar via
locality-sensitive hashing and clustering\citep{hanHyperAttentionLongcontextAttention2023}. A second
one is flash-\textbf{softpick} \textbf{attention}, a rectified softmax
that decreases hyperactivation of specific tokens, often called
attention sinks\citep{zuhriSoftpickNoAttention2025}. We also present our own
sub-quadratic attention mechanism: \textbf{criss-cross attention} (see \hyperref[methods]{Methods}),
inspired by advanced concepts such as the Recurrent Interface Network
(RIN) and the Induced Set Attention Block (ISAB)\citep{leeSetTransformerFramework2019,jabriScalableAdaptiveComputation2023}.
It compresses attention by sketching it in context, using a doubly
cross-attention mechanism with a set of latent tokens that get updated
across layers (see Supplementary Figure~\ref{fig-s17-illustration-of-criss-cross-attention}). We show that only criss-cross
attention dramatically improved the model' s speed while
retaining all its abilities (see Table \ref{tab:additive_benchmark}). However, it is not yet
compatible to retrieve gene networks from; for this reason, our
\gls{scPRINT}-2 architecture, for now, uses flash-attention-3 and XPressor.

On another direction, while single-cell analysis has leveraged \gls{VAE}s for
years to generate meaningful compressed representations of cells,
transformers inherently lack this ability\citep{lopezDeepGenerativeModeling2018,moinfartUnsupervisedDeepDisentangled2025,xuProbabilisticHarmonizationAnnotation2021}. We
use the \textbf{XPressor} architecture presented in Kalfon et
al.\citep{kalfonTowardsFoundationModels2025}, which compresses output gene embeddings into a
set of cell embeddings and decompresses them back into their original
gene embeddings (see Figure \ref{fig:scprint2_overview}, Figure \ref{fig:scprint2_xpressor}, and
\hyperref[xpressor-model]{Methods}). This innovative architecture
draws on ideas that have existed in the transformer literature for
several years\citep{jabriScalableAdaptiveComputation2023,jaeglePerceiverIOGeneral2022,jaeglePerceiverGeneralPerception2021,carreiraHiPHierarchicalPerceiver2022,leeNVEmbedImprovedTechniques2025}. We show in our ablation study
that using XPressor results in a slightly better cell representation
overall, but does not meet the statistical threshold. This difference
might be explained by the limit in the number of epochs and the model's
smaller size compared to Kalfon et al. (see Table \ref{tab:additive_benchmark}, see Supplementary Table~\ref{table-s1-detailed-version-of-the-additive-benchmark}). We include an extension to this approach, in which one appends \gls{VAE}s
to each output embedding of XPressor to regularise the different cell
embeddings generated by the model (see Figure \ref{fig:scprint2_xpressor}). This addition allows
us to choose a specific dimension for each cell embedding that is lower
than that of XPressor. A second constraint is defined by applying the
Kullback-Leibler divergence (KL) loss (see Figure \ref{fig:scprint2_overview}, see
\hyperref[vae-based-compressor-model]{Methods}). This creates an
information bottleneck for the different cell embeddings, pushing the
model to select only the minimum amount of relevant information to
represent the label. While our ablation study does not show improvement
in cell embeddings with this approach, this is likely because each
method was trained for only 20 epochs. Indeed, the VAE-infused model is
taking longer to learn to classify cells. However, the batch correction
score improved significantly, indicating that the different cell tokens
mainly contained information about the class they encoded (see Supplementary
Materials). Now that we have highly compressed cell-level embeddings
(i.e., tokens), we can apply a \textbf{dissimilarity loss} between each
for a given cell. This actively pushes them to be as different as
possible (see Supplementary Figure~\ref{fig-s18-illustration-of-the-similarity-and-dissimilarity-based-contrastive-losses-used-in-scprint-2}; see
\hyperref[embedding-independence-loss]{Methods}). We demonstrate
that this tends to slightly improve the model' s output
embedding in our ablation study (see Table 1).

These architectural changes make scPRINT-2 much more efficient at
compression and zero-shot batch-correction. Indeed, on the open
problem's benchmark, we observe an overall improvement over scPRINT-1,
again becoming the state-of-the-art zero-shot method on the platform
(see Figure \ref{fig:scprint2_xpressor}). This zero-shot performance increase is solely due to
the improvement in the batch-correction score from using our \gls{VAE} method
(see Supplementary Figure~\ref{fig-s19-whisker-plot-of-open-problems-batch-integration-with-batch-correction-only-scores}). We then fine-tune the XPressor architecture alone
-- our XPEFT approach -- to further learn to remove batch effects and
predict expert-annotated cell-type labels. We add a Maximum Mean
Discrepancy (MMD) loss (see \hyperref[fine-tuning-task]{Methods})
that penalizes the distance between batch
elements\citep{ouyangMaximumMeanDiscrepancy2022,zhangSingleCellDataAnalysis2019}. Doing so, we observe a jump in scIB
scores, especially in biological truthfulness, as measured by the scIB
metrics (see Figure 4C; Supplementary Figure~\ref{fig-s20-whisker-plot-open-problems-batch-integration-with-bio-conservation-only-scores}), making \gls{scPRINT}-2 the
best-performing method in the benchmark.

\subsubsection{scPRINT-2 generalizes to unseen cell embedding
tasks}\label{scprint-2-generalizes-to-unseen-cell-embedding-tasks}

We then wanted to push our analysis further and test the zero-shot
organism-level integration of \gls{scPRINT}-2 on organisms unseen during
training. Again, using our cat and tiger dataset presented in the
\hyperref[a-diverse-dataset-of-350-million-cells-pushes-generalization-to-unseen-organisms]{second
result section}\textbf{,} we saw that already, \gls{scPRINT}-2's general cell
embedding performs better than doing no correction and keeps lot of
biological truthfulness, as shown by the \gls{scIB} score of 0.44 vs 0.37 for
PCA (see Figure \ref{fig:scprint2_xpressor}, see Supplementary Figures~\ref{fig-s21-umap-of-scprint-2s-zero-shot-multi-species-expression-embedding-using-the-full-cell-embedding}, \ref{fig-s22-barplot-of-scib-score-on-scprint-2s-multi-species-integration}, see Supplementary Table~\ref{table-s4-detailed-scib-scores-on-the-unseen-species-integration-task}).
Then, as often, taking the cell-type-specific embedding further
increases the biological truthfulness to 0.49, mainly by generating a
more faithful biological representation, as reflected in the \gls{scIB} scores
(see Figure \ref{fig:scprint2_xpressor}, Supplementary Figures~\ref{fig-s22-barplot-of-scib-score-on-scprint-2s-multi-species-integration}, \ref{fig-s23-umap-of-scprint-2s-zero-shot-multi-species-expression-embedding-using-the-cell-type-cell-embedding}, Supplementary Table~\ref{table-s4-detailed-scib-scores-on-the-unseen-species-integration-task}). Again, using
XPEFT, we achieve a tremendous 0.60 \gls{scIB} score, placing us among the top
3 best-performing models in this category, behind SATURN and scGEN (see
Figure \ref{fig:scprint2_denoising}, Supplementary Figures~\ref{fig-s22-barplot-of-scib-score-on-scprint-2s-multi-species-integration}, \ref{fig-s24-umap-of-scprint-2s-multi-species-expression-embedding-post-finetuning-using-the-full-cell-embedding}, Supplementary Table~\ref{table-s3-detailed-scib-biological-conservation-scores-on-the-xenium-dataset}). We note that even in
this domain, many cell types didn't overlap across organisms. It is a
common behavior in this benchmark, and similar cell types now almost
overlap in the \gls{UMAP}, hinting at shared neighbors (see Figure \ref{fig:scprint2_denoising}, see
\hyperref[embedding-task]{Methods})\citep{mcinnesUMAPUniformManifold2020}.

Finally, we wanted to examine the model's ability not only to integrate
cellular profiles but also to generate entirely new ones at inference
time in a zero-shot manner by combining cell tokens (see Figure \ref{fig:scprint2_xpressor}). We
first approach it using a matched mouse-human multi-organ atlas from
Zhong et al.\citep{zhongBenchmarkingCrossspeciesSinglecell2025}. We then generated cell embeddings for
all cells and computed an average ``human''-ness cell embedding using
the \emph{organism} embeddings of all human cells. We regenerate an
expression profile using 1. the human gene embedding and 2. the mouse
cell embeddings, replacing the organism cell embedding with the human
one (see Figure \ref{fig:scprint2_xpressor} and \hyperref[generative-task]{Methods}). We
thus generate a set of human-like cell expression profiles from mouse
expression profiles. Using the 5000 most variable orthologous genes, we
indeed observed a decrease in the Wasserstein-2 (W2) distance on this
counterfactual conversion to human (see Figure \ref{fig:scprint2_xpressor}, see
\hyperref[scrna-seq-datasets-distances]{Methods})\citep{flamaryPOTPythonOptimal2021,peyreComputationalOptimalTransport2020}.
Applying a similar approach, but this time to generate females from
males in the human dataset, we also notice a similar reduction in
expression W2-distance from 1076 to 938.

Looking at how cell expression patterns change after this transition, we
found that most of the top differentially expressed genes are the same
as those identified in the differential expression analysis of the real
human dataset (see Figure \ref{fig:scprint2_xpressor}, see Supplementary Figure~\ref{fig-s25-differential-expression-plot-of-the-human-vs-mouse-dataset-from-section-4}). Computing an
over-representation test, we observe a robust 58\% enrichment compared
to random, with more than half of the top differentially expressed genes
correctly predicted by \gls{scPRINT}-2 in both over- and under-expressed genes
(see Figure \ref{fig:scprint2_xpressor}, see Supplementary Figures~\ref{fig-s26-over-representation-plot-of-humanized-mouse-data-vs-real-mouse-data-compared-to-human}, \ref{fig-s27-over-representation-plot-of-female-like-male-data-vs-real-female-data-compared-to-male}). Looking at
\emph{Reactome\_2022} pathway enrichments, we see multiple pathways
related to immune system function, membrane-\gls{ECM} (Extra-Cellular Matrix)
interactions, and tissue elasticity, as well as many other
molecular-level pathways (see Supplementary Figure~\ref{fig-s28-dot-plot-of-gene-set-enrichment-analysis-over-the-differential-expression-analysis-of-section-4}). These align with
previous analyses highlighting \gls{ECM} and immune function differences
between human and mouse tissues\citep{wangComparativeAnalysisHuman2024,heGenomicPerspectiveAging2023}.

Overall, we have shown that an entirely novel architecture and a set of
learning constraints enable \gls{scPRINT}-2 to generate high-quality
embeddings in a zero-shot manner. Thanks to its multi-organism training,
this can be extended to unseen species, while achieving even stronger
results with fine-tuning. We have also demonstrated how one can use the
\gls{scPRINT}-2's cell embeddings to generate counterfactual cellular
profiles. This makes it a strong contender for performing atlas-scale
analysis across tissues, diseases, and organisms, by learning to
disentangle each cell component. We will now see how other parts of the
models can be used to extract additional information.

\subsection{High-quality contextual gene representations from
scPRINT-2}\label{high-quality-contextual-gene-representations-from-scprint-2}

\subsubsection{scPRINT-2 has rich gene
embeddings}\label{scprint-2-has-rich-gene-embeddings}

\gls{scFM}s don't just provide cell-level embedding, they have also been used
to generate contextual gene-level embeddings given a cell's expression
profile or to predict gene-gene connections. The model' s
gene embeddings can be used for fine-tuning, such as to predict \gls{ATAC-seq}
activities or gene essentiality\citep{cuiScGPTBuildingFoundation2024,theodorisTransferLearningEnables2023}. We investigate the
gene embeddings produced by \gls{scPRINT}-2 and then delve into how its gene
networks can be better extracted and assessed.

A good output gene embedding is also defined by the quality of its
input. With \gls{scPRINT}-2, we introduced a fine-tuning adapter layer on top
of \gls{ESM}3's protein embeddings, jointly trained with the model (see \hyperref[methods]{Methods}).
This approach is one of the few that improve gene network inference
without decreasing any other metrics in our additive benchmark (see
Table \ref{tab:additive_benchmark}). It allows us to update gene representations during
pre-training while maintaining the ability to work with unseen
representations, e.g., from unseen species (see Figure \ref{fig:scprint2_genenetwork}).

It remains unclear, however, what the right approach is for selecting
output gene embeddings, with some heuristics proposing using the last or
second-to-last layer. Using our regular transformer model trained with
masking, we demonstrate that its output gene embeddings contain only
their own expression values (see Figure \ref{fig:scprint2_genenetwork}). However, when trained with
the Xpressor architecture, clusters of genes appear (see Figure \ref{fig:scprint2_genenetwork}).
This is sensible because Xpressor forces gene embeddings to be rich in
meaning, as the compression block must query them. We have, however,
noticed that for regular models that are not fully trained (only
20 epochs), the output gene embedding still contains some input \gls{ESM}3
features (see Supplementary Figure~\ref{fig-s29-output-gene-embedding-for-a-non-fully-trained-model-without-xpressor-architecture}). The number of enriched pathways in its
output gene embedding cluster is still significantly less than for
\gls{scPRINT}-2's XPressor architecture (see Figure \ref{fig:scprint2_genenetwork}; see
\hyperref[assessment-of-gene-output-embeddings]{Methods})

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/scprint2/image3.png}
    \caption[Presentation of the ESM3 fine-tuning and gene network study]{(a) Illustration of fine-tuning of ESM3 while training \gls{scPRINT}-2 using an adaptor layer. (b) Comparison of gene output-embeddings for a random cell in a model with the XPressor architecture and a model trained without. (c) On the side, the average number of pathways shown to be enriched in the gene output embedding clustering of each method using three main pathway databases. The number below is on the non-fully trained regular transformer; otherwise, no pathways are enriched (see Methods). (d) Comparison of ground truth networks' overlap between cellmap, the human interactome, and genome-wide perturb-seq. (e) Benchmark over six ground truth gene networks of scPRINT-1's gene networks with its extraction method and \gls{scPRINT}-2's gene networks with its extraction method, over nine different human cell types from the same dataset. (f) Comparison of the top-30 hub nodes on both gene networks. Arrows link similar genes, and colors represent similar gene groups. (g) Subset of a gene network generated by \gls{scPRINT}-2 seeded at FTL1, on human macrophage cells, and on mouse macrophage cells, edge color represents the RoseTTAFold2-PPI scores for these connections, grey means no score was computed. The AlphaFold-Multimer structure and amino-acid distance map are provided for the star-marked connections. Source data are provided as a Source Data file.}
    \label{fig:scprint2_genenetwork}
\end{figure}

\subsubsection{extracting gene networks from
\gls{scPRINT}-2}\label{extracting-gene-networks-from-scprint-2}

Thanks to the transformer architecture, one can go beyond gene output
embeddings to examine gene-gene interactions via the model's attention
layers. Following the tests reported in Kalfon et al., we observed, on
average, no dramatic performance gains across the methods we tested (see
Table \ref{tab:additive_benchmark}). An issue we noticed is that the problem is not well-defined.
Indeed, the ground truths widely disagreed with one another (see Figure
\ref{fig:scprint2_genenetwork}; see \hyperref[gene-network-task]{Methods}).
Between the genome-wide perturb-seq (\gls{gwps}) ground truth and omnipath,
only 800 gene-gene connections were in common over the hundreds of
thousands that each contained. This suggests that diversity of ground
truth will be key to showcasing the breadth of potential gene-gene
connections in the cell.

We thus gathered a new set of ground truth gene networks (\gls{GN})s from
recent works. Our first approach was to use protein-binding datafrom
\gls{AP-MS} experiments within the O2US cell line, called the
\emph{cellmap}\citep{schafferMultimodalCellMaps2025} (see
\hyperref[gene-network-task]{Methods}). Additionally, thanks to
protein structure models, we are now able to compute putative
interactions across millions of protein pairs; a first version of this
analysis has been defined in the human \emph{interactome} (see
\hyperref[gene-network-task]{Methods}). But here again, the
disagreement was significant, with only \textasciitilde1-4\% of the
connections in each ground truth being found in another, and no
connections were reliably found across all five ground truths (see Supplementary
Figure~\ref{fig-s30-venn-diagram-of-the-different-ground-truth-gene-networks}).

Acknowledging these disagreements, we benchmarked them against nine
human cell types from the same dataset using scPRINT-1 and \gls{scPRINT}-2. We
use a gene network extraction method that is more computationally
demanding but biases the network towards co-expressed genes (see
\hyperref[extracting-meta-cell-gene-networks-from-attention-matrices]{Methods}).
We see that \gls{scPRINT}-2's performance was often greater or similar across
all benchmark networks, as indicated by the odds-ratio measures (see
Figure \ref{fig:scprint2_genenetwork}; see \hyperref[gene-network-task]{Methods}).
We did not see a similar trend, however, on \gls{AUPRC} (see Supplementary Figure~\ref{fig-s31-whisker-plot-of-auprc-ratio-scores-for-scprint-1-and-scprint-2}). This suggests that our method is more accurate for its top-K
connections. Indeed, the strongest human interactome connections were
overrepresented in \gls{scPRINT}-2, more so than in \gls{scPRINT}-1.

\subsubsection{cross-organism gene network
analysis}\label{cross-organism-gene-network-analysis}

To continue on our cross-organism analysis, we also aimed to further
characterize some of the genes observed in our previous human/mouse
datasets by interrogating the cell-specific GN identified by \gls{scPRINT}-2
in \emph{Macrophage} cells from both mammals. Looking at their hub
nodes, we see that many are common and represent key conserved cell
immune pathways, such as \emph{feroptosis}, \emph{vitamin B12}, and
\emph{Pathogen Phagocytosis Pathways} (\emph{WikiPathway\_2023\_Human}),
with genes like \emph{C1Qs, RPs, ALB, and APOE}\citep{mesquitaHFerritinEssentialMacrophages2020,bockAhReceptorVitamin2024}.
These mainly relate to the macrophage' s internal
machinery, which is designed to eat and destroy pathogens. Other genes
were clear markers of macrophages (\emph{CD74;LYZ) and/or immune cells
(HLA-DRA, B2M) or their pathways, such as interferons alpha/gamma and
MHC Class II (MSigDB\_Hallmark\_202076--78)}. Interestingly, these
networks share only 30\% similarity when considering the top 20
connections for each gene. But what seemed like differences in
connections and top 50 hub genes tended to disappear after thorough
analysis, such as with the Ribosomal proteins, which are related in the
kinds of pathways they are part of, or in their relationships in the
PPI\_Hub\_Proteins database\citep{fangGSEApyComprehensivePackage2023} (see Figure \ref{fig:scprint2_genenetwork}).

We then extracted a subset of the macrophage networks, seeded at the
\emph{FTH1} gene, for both organisms, focusing on the top 15 connected
nodes and their top 60 edges (see Figure \ref{fig:scprint2_genenetwork}; see
\hyperref[plotting-gene-sub-networks]{Methods}). We observed a set
of hub genes in both subnetworks, with some genes being shared between
human and mouse. Interestingly, these hub genes had more interactions in
the human interactome ground truth than non-hub genes. We also noticed
that the ``hub-ness'' of the subnetworks can be very variable and seems
to depend on the ``seed'' gene (see Supplementary Figure~\ref{fig-s32-additional-scprint-2-generated-gene-network-computed-from-cdc45}).

By overlaying the human interactome ground-truth values on our
subnetworks, we found that only a small subset of connections was marked
as valid (i.e., score above 0.6) in the ground truth (see Figure \ref{fig:scprint2_genenetwork}). In
the mouse \emph{Macrophage} subnetwork, almost no connections were
recovered, but this may be explained by the fact that the ground truth
is the ``human'' interactome, computed using human proteins rather than
mouse proteins. We thus wondered whether we could use \gls{scPRINT}-2 to
cross-validate the interactions present in this ground truth. Indeed, we
know that the human interactome values are not directly computed from
AlphaFold-multimer's interaction probability (\gls{ipTM}); they come from a
simpler model called ``RoseTTAFold2-PPI''. Testing a couple of
connections predicted to be low \gls{ipTM} by RoseTTAFold2-PPI but found by
\gls{scPRINT}-2, we readily identified two: HLA-DRA/CD74 and B2M/B2M, which,
when passed to AlphaFold-Multimer, indeed formed an interaction with an
\gls{ipTM} of more than 0.6. This showcases the potential of \gls{scPRINT}-2 in this
domain and future directions for \gls{GN} inference.

We have seen here how \gls{scPRINT}-2's output gene embeddings and attention
matrices can be used to extract meaningful biological insights and drive
hypothesis generation in a cell-to-cell, state-specific manner. These
outputs can also be used for fine-tuning purposes and in explainable
AI-driven analysis. We also pushed our \gls{GN} analysis further, defining
additional benchmarks and a more powerful \gls{GN} extraction mechanism. We
demonstrated cross-species analysis and presented the tantalizing
possibility of merging foundation models at different scales, including
\gls{ESM}3 fine-tuning, AlphaFold Multimer, RoseTTAFold2-PPI, and \gls{scPRINT}-2.
While these are just examples, they demonstrate what aggregating
multiple bodies of evidence across scales can achieve for genetic
interaction predictions. A first step towards using \gls{scFM}s, protein
Language Models, and structural models in coordination, to shed light on
the cellular machinery.

\section{Discussion}\label{discussion}

In this work, we present a gymnasium of tasks to benchmark \gls{scFM}s in
multiple contexts. Together with an efficient and reproducible pipeline,
we test the benefits of 42 different parts of \gls{scFM}s structures,
encoding, and training. In this additive benchmark, 12 of these are our
own contributions to \gls{scFM}s, including \gls{GNN}-based expression encoding,
cross-foundation model fine-tuning, sub-quadratic attention mechanisms,
and rich losses. This massive benchmark is the first of its kind for
\gls{scFM}s and assesses four different tasks. It allowed us to identify
bottlenecks and limitations, issues that we solved in subsequent
analysis. Indeed, future benchmarks will benefit from using more diverse
datasets, tasks, and ground truths.

We have also presented the largest pre-training database to date,
encompassing more organisms, conditions, and data modalities. We have
seen that, while more work is needed to obtain higher-quality,
well-annotated datasets, our dataloader and preprocessing pipeline have
made the most of this vast database.

Using the best feature combinations from our additive benchmarking, we
build and train a next-generation cell Foundation Model, \gls{scPRINT}-2. We
demonstrate that, although currently 5 times smaller, \gls{scPRINT}-2
outperforms \gls{scPRINT}-1 across all benchmarks tested. On denoising,
\gls{scPRINT}-2 becomes state-of-the-art, and with our fine-tuning approach,
it also outperforms every other method on the batch-correction and
classification tasks of the open-problem benchmarks.

We then challenge \gls{scPRINT}-2 on tasks of high relevance for cellular
biology, highlighting some pitfalls in current benchmarks. We show that
\gls{scPRINT}-2 acquires generalizable abilities across unseen modalities and
organisms, while remaining consistent in its predictions. We demonstrate
it across many tasks, including cross-organism integration, unseen gene
imputation, and counterfactual reasoning.

Finally, we present tools for easily extracting labels, cell-specific
gene embeddings, imputing gene expression, performing gene network
inference, and working with organisms unseen during pre-training. We
believe our results demonstrate many domains where \gls{scFM}s might
confidently replace approaches that rely on heuristics, atlases, and a
variety of tools and packages. However, much work remains.

Current ground-truth cell annotations are cluster-based and obfuscate
the complexity of cellular states by inherent clustering biases. Batch
correction metrics are similarly biased, and top scores can be easily
gamed; gene network ground-truths are not cell type specific and likely
filled with false negatives. Data diversity and quality are the
principal pre-training bottlenecks, and efforts will be needed to
improve foundation models. Many other key modalities, such as measuring
time and perturbation effects, remain scarce. They will become
increasingly helpful for enriching the future comprehensive benchmarks
of next-generation cell foundation models.

Our analysis and contributions highlight powerful features of \gls{scFM}s and
provide guidance for designing benchmarks that better highlight their
strengths and weaknesses. \gls{scPRINT}-2 presents a direction for future
improvements, with more specialized architectures and using a
combination of biological FMs working jointly across modalities and
scales. This next-generation \gls{scFM} is a step forward in the design of AI
for cell biology.
