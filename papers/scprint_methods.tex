\section{Methods}
\label{sec:methodsprint}

we propose scPRINT, a foundation model designed for gene network inference. ScPRINT brings novel inductive biases and pretraining strategies better suited to GN inference while answering issues in current models. scPrint outputs cell type-specific genome-wide gene networks but also generates predictions on many related tasks, such as cell annotations, batch effect correction, and denoising, without fine-tuning.

\subsection{Architecture}\label{architecture}

The model architecture is composed of:

\begin{itemize}
\item
  An encoder that takes the raw data and embeds it in a high-dimensional
  space used by the transformer.
\item
  A bidirectional multi-head transformer
\item
  A decoder to transform the expression embeddings into expression
  values
\item
  A decoder that transforms the cell embeddings into cell-specific label
  prediction over a range of classes.
\end{itemize}

\subsubsection{Expression encoder}\label{expression-encoder}

In scPRINT, each gene in a cell is converted to an embedding: It
corresponds to the sum of 3 different elements:

1. An embedding representing the gene itself (see Supplementary Table \href{table-s1-list-of-novelties-in-scprint-and-comparison-to-scgpt-and-scfoundation} for model embedding size). ESM2 embedding of each gene's most common protein product was used to represent that gene. While imperfect in some ways, this inductive bias allows the model to learn representations that potentially apply to even unseen genes from unseen species or integrate specific genetic mutations into its representation. First implemented in UCE, this provides the model information related to the gene product's structure, ontology, and similarity to other genes. This also speeds up the training greatly, particularly for small models. We show that this is a great gene representation, but that model performance can be increased by refining gene embeddings further during training. However, we elect not to do so to maintain the model's versatility in working on unseen genes.

We encode the genes' embeddings using ESM2. The mapping process happens the following way:

\begin{itemize}
\item
  A gene name is mapped to its canonical protein name using Ensembl.
\item
  We recover the protein sequence of the protein using Ensembl
\item
  We use the protein sequence to generate an embedding using ESM2 by averaging all the amino-acid output embeddings, as done in the ESM2 paper.
\end{itemize}

With the embedding function provided in our code, one can easily do this with any species in Ensembl.

scPRINT can effectively be retrained with any set of gene embeddings, which can be frozen during training or used only for initialization (tried, for example, in our ablation studies, Table S3).

2. An embedding of the gene location in the genome. This has also been proposed in UCE and helps the model understand that genes with similar locations tend to be regulated by similar regulatory regions, a relationship well-known in cellular biology.

We encode the genes' locations using positional encoding. Every gene less than 10,000 bp from the next is said to be in the same location; otherwise, we increment location by 1. We do this for all genes in the Ensembl database per species.

We then embed these locations by applying the Positional Encoding (PE) algorithm of Vaswani et al. .

3. An embedding of the gene expression in the cell. For this, we embed
the gene's expression using an MLP. While GeneFormer devised a ranking
strategy based on a gene expression compared to a baseline expression,
scGPT instead used binning of log normalized counts. On our end, we
haven't found that this approach was the simplest, nor was it performing
better than only using the log-transformed counts. We thus directly take
the log-transformed counts

\begin{equation}
\mathbf{e}_{\mathbf{i,j}} = MLP(log_{2}(x_{i,j} + 1)),\ x_{i,j} \in \mathbb{R},\ \mathbf{e}_{\mathbf{i,j}} \in \mathbb{R}^{d}
\label{eq:expression_embedding}
\end{equation}

where \(\exp r_{i,j}\ \)is the embedding of the expression, \(x_{i,j}\)
is the expression value of the gene j in the cell i, and the MLP is a
two-layer neural network, where each layer is composed of

\begin{equation}
Dropout(ReLU(LayerNorm(Linear(\mathbf{e}_{\mathbf{i,j}}))))
\label{eq:mlp_layer}
\end{equation}

where the Dropout rate is fixed at 0.1, and the dimensions are specified
as 1 → \emph{d} for the first layer of the MLP and \emph{d → d} for the
second layer, with d representing the model dimension.

Of Note: Geneformer used positional encoding to encode gene expression,
a function often used to encode the position of words in a text.
Similarly to gene name token, scGPT learned an embedding for different
ranges of expression values, binning them to remove sampling noise.

Both approaches apply a specific prior for the metric that defines
expression. Geneformer defines expression amount as ranking based on how
each gene is expressed in the cell compared to its average across all
cells. Unregarding the batch effect issues, this is an assumption that
expression values are not meaningful and only the ranking of the
relative abundance is meaningful information. Meanwhile, scGPT has the
bias that an expression of 1, 2, or 3 are the same and that an
expression 1, and 5 are different by some amount learned by the model.

By using an MLP with two layers, we effectively let the model learn the
metric of transcription expression. Moreover, again, we decrease the
number of parameters used compared to scGPT while being able to make
predictions on count values unseen during training, such as those of
bulk or pseudo-bulk RNAseq.

Finally, when encoding a cell expression profile, only a subset of 2200
genes is used during pretraining. If less than 2200 genes are expressed,
we randomly choose 2200 expressed genes and pad them with randomly
sampled unexpressed genes (meaning with an expression value of 0). This
approach allows the model to see different patches of the same cell
profile during training. We chose 2200 genes as 2/3rds of the cells in
cellxgene had less than this number of genes expressed, striking a
balance between computation and gene usage.

We decided to add unexpressed genes because, combined with our denoising
methodology, this lets the model figure out that some genes are true 0s
during training. In contrast, others are only caused by dropout and a
function of the transcript counts. This causes scPRINT to model dropout
as a function of read depth (i.e., total transcript count).

Moreover, this completes the minibatch by token matrix without padding
and fully utilizes the GPU during the attention computation.

Of note, some models have been able to reach context lengths of 20,000
genes using the performer architecture. Performer is an often-cited
method and part of the literature on attention approximation. However,
most state-of-the-art transformer models do not use attention
approximation as they are known to lead to worse
performance.

Moreover, in cellxgene, more than 80\% of the cells have less than 2200
genes being measured. This means that most of the memory and compute
power is likely lost on tokens that are almost always zeros due to
dropout.

The full set of embeddings of cell i sent to the transformer is the
matrix \(X_{i}\) where

\begin{equation}
X_{i} = [\mathbf{g}_{\mathbf{0}} + \mathbf{e}_{\mathbf{i,0}} + \mathbf{l}_{\mathbf{0}}, \mathbf{g}_{\mathbf{1}} + \mathbf{e}_{\mathbf{i,1}} + \mathbf{l}_{\mathbf{1}}, ..., \mathbf{e}_{\mathbf{i,t}}, \mathbf{p}_{\mathbf{default}}, \mathbf{p}_{\mathbf{celltype}}, \mathbf{p}_{\mathbf{disease}}, ...]
\label{eq:cell_embeddings}
\end{equation}

where \(\mathbf{g}_{\mathbf{j}}\) is the gene j encoding,
\(\mathbf{e}_{\mathbf{i,j}}\) is the encoding of the expression of gene
j in cell i, \(\mathbf{l}_{\mathbf{j}}\) is the gene j location
encoding, and \(\mathbf{p}_{\mathbf{A}}\) is a learnt embedding for the
class A.

The total count information is stored separately and encoded similarly
to the expression,

\begin{equation}
\mathbf{e}_{\mathbf{t,i}} = MLP(log_{2}(1 + t_{i})), \text{ where } t_{i} = \sum_{j}x_{i,j}
\label{eq:total_count}
\end{equation}

with \(x_{i,j}\) the expression value of gene j in cell i, and the MLP
is a two-layer neural network similar to the previous one.

The full cell total count (\(t\)) lets scPRINT model its denoising based
on this required total count parameter.

The placeholder tokens (total count, default cell embedding, cell type,
disease, sex, ethnicity, assay, organism) are learned embeddings that
stay the same across all inputs. They only act as placeholders for the
model to fill in during the forward process. At the transformer's
output, they will have been modified to contain the embeddings
requested. At least two are used, one containing the default cell
embedding and another the profile's total depth. More tokens can be
used, one for each predicted cell label.

\subsubsection{Model}\label{model}

The model is a bidirectional autoencoder similar to
BERT with \emph{n} layers, \emph{h} attention heads,
and a dimension of \emph{d}. It uses the
flashattention2 methodology implemented in Triton to
compute its attention matrix. It uses the pre-normalization
technique, with a sped-up layer norm implemented in
Triton's tutorial. It uses a stochastic depth with
increasing dropout probability.

It has a 2-layer MLP with a 4x width increase in its hidden layer and a
GELU activation function.

\subsubsection{Expression decoder}\label{expression-decoder}

scPRINT uses a novel expression decoder for foundation models, which
outputs the parameters of a zero-inflated negative binomial
(\emph{ZiNB}) function for each gene \emph{i} in cell \emph{j}. The
\emph{ZiNB} distribution is defined as

\begin{equation}
X \sim ZiNB(\mu, \theta, \pi)
\label{eq:zinb_dist}
\end{equation}

where the parameters \(\mu,\ \theta,\ \pi\) are obtained from a
multi-layer perceptron (MLP) applied to the expression embeddings
outputted by the transformer model at its last layer (e), which are the:

\begin{equation}
\mu, \theta, \pi = MLP(\mathbf{e})
\label{eq:zinb_params}
\end{equation}

The MLP is a two-layer neural network with dimensions {[}\emph{d, d},
3{]}

Based on the work of Jiang et al., zero inflation is
the best distribution when considering a broad range of transcriptomic
measurements, where some have enough dropouts, and a zero inflation term
is needed to model it. In our case, and similarly to
scVI, we define our \emph{ZiNB} as

\begin{equation}
ZiNB(x | \mu, \theta, \pi) = \pi\delta_{0}(x) + (1 - \pi)NB(x | \mu, \theta)
\label{eq:zinb_def}
\end{equation}

where \(\delta_{0}(x)\) is a point mass at zero, and
\(NB(x\ |\ \mu,\theta)\) is the negative binomial distribution with mean
\(\mu\) and dispersion \(\theta\).

With these parameters, the negative binomial distribution is represented
in the following way

\begin{equation}
NB(x | \mu, \theta) = \frac{\Gamma(x + \theta)}{x!\Gamma(\theta)}\left(\frac{\mu}{\mu + \theta}\right)^{x}\left(\frac{\theta}{\mu + \theta}\right)^{\theta}
\label{eq:nb_dist}
\end{equation}

where \(\mu\) is the mean and \(\theta\) the overdispersion parameter,
representing the inverse of the dispersion. From Hibe et
al., we know that this is a parameter change from
the most used probability mass function (PMF) given by

\begin{equation}
P(X = x) = \binom{x + r - 1}{x}(1 - p)^{r}p^{x}
\label{eq:pmf}
\end{equation}

where r is the number of successes, \emph{p} is the probability of
success, and \emph{k} is the number of failures.

One can interpret such a negative binomial distribution as a Poisson
distribution with an additional overdispersion term that makes the
variance not tied to the mean. In scPRINT, we use the zero-inflated
Poisson for count downsampling as we can't easily infer the gene
overdispersion parameter from each cell profile. By removing this
zero-inflated Poisson from the gene expression profile, we keep the
potential overdispersion in the profile (see the
\hyperref[negative-binomial-to-poisson-relationship]{Negative Binomial
to Poisson relationship} section in Methods).

Compared to scVI, where the overdispersion parameter \(\theta\) is
learned for each gene, we make scPRINT output it together with
\(\mu,\ \pi\) (see Supplementary Figure \ref{fig-s13-graphical-model})

Effectively, the model learns that the dispersion might change depending
on the gene, the sequencer, the cell type, and the sequencing depth.

\subsubsection{Class decoder}\label{class-decoder}

scPRINT also outputs a variety of class embeddings, such as default cell
embedding, cell type embedding, disease embedding, etc., by filling the
different placeholder tokens given as input (see the
\hyperref[expression-encoder]{Expression encoder} section in the
Methods).

Effectively, for each class, we have the model learn to produce a new
disentangled embedding (e.g., cell type, disease, tissue, age). This
means the model uses an MLP to transform each token where A is a class.
For each, we jointly train a classifier:

\begin{equation}
\widehat{\mathbf{c}_{\mathbf{A}}} = \sigma(MLP_{A}(\widehat{\mathbf{e}_{A}}))
\label{eq:classifier}
\end{equation}

where:

\begin{itemize}
\item
  \(\widehat{\mathbf{c}_{A}}\ \)represents the logits for a class A of a
  dimension \(d_{A}\) whose size corresponds to the number of labels.
\item
  \(\sigma\) denotes the Sigmoid activation function.
\item
  \(MLP_{A}\) stands for the Multi-Layer Perceptron trained to predict
  the logits of the class \emph{A.}
\item
  \({\widehat{\mathbf{e}}}_{A}\) is the output embedding for the class A
  of dimension \emph{d}.
\end{itemize}

However, some classes, like cell type, have up to 800 labels.
Fortunately, cellxgene classes follow an ontology, a robust structure
that defines relationships among the labels. We reduce the size of the
output labels by training the model only on the leaf labels in the
ontology hierarchy (i.e., the most precise available). For cell types,
this represents around 400 different labels (see Supplementary Table \ref{table-s13-number-of-elements-predicted-per-class}).

Thus, when a label is not very specific for a cell type (e.g., neuron),
the model will predict the best leaf label (e.g., dopaminergic neuron).
This way, we can generate meaningful training signals from even very
coarse labels (see \hyperref[the-classification-task]{The classification
task} section in methods for more information and definition of the
loss). We only apply this hierarchical classifier to the cell type,
disease, and assay labels.

In the following section, we show how we train such classifiers. During
the classifiers' training, we sum up their loss without
applying any scaling between the different classes.

\subsection{Ablation study}\label{ablation-study}

We perform an ablation study of multiple of our additions in scPRINT for
its medium size version. Removing positional encoding, replacing
log-normalization with a total-normalization, replacing denoising with
masking, using the cell-gene product method of scGPT vs our own
encoder-decoder approach to learn a cell embedding, using 2 vs 4 heads
per attention blocks, not using weighted random sampling, not freezing
the gene ID embeddings, and using mean-squared-error instead of the ZINB
loss. For each, we re-train scPRINT entirely on the same dataset and
validate its test performance with our automated benchmark platform. We
provide the results in Table S3.

\subsection{Pretraining}\label{pretraining}

The three tasks of the multi-task pretraining are the denoising task,
the classification task, and the bottleneck learning task. While the
denoising loss enhances the model's ability to find
meaningful gene-gene connections, the other two try to make the model
and its underlying networks more robust and cell-type-specific. All
three losses are summed without rescaling.

\subsubsection{Optimization method}\label{optimization-method}

The optimization is done with fused ADAMW, with a weight decay of 0.01.
We noticed a total inability to learn when using base ADAM, which has a
similar weight decay. This can be explained by a known inequivalence
issue in ADAM.

We use the stochastic weight averaging method
during training with a learning rate of 0.03.

During pre-training, the hyperparameters are set to dropout of 0.1, a
learning rate (LR) of 1e-4, the precision is set to 16-mixed with
residuals in fp32. We clip gradients to 100 and train in many sub-epochs
of 7000 training batches and 2000 validation batches with a warmup
duration of 500 steps.

Across epochs, we use a linear LR decrease of 0.6 with a patience of 1
and stop training after three consecutive increases in validation loss
(patience: 3). In the final layer of the class decoders, we initialize
values to a normal distribution around 1 for weights, 0 for biases, and
-0.12 for biases.

Our batch size is 64, and we use a pre-norm strategy for the transformer
with a linearly increasing stochastic depth dropout rate of 0.02 per
layer. We use a noise parameter of 60\%. We split the cells in the
datasets into 98\% train and 2\% validation and reserve at minimum 2\%
of separated datasets for testing.

Finally, we use weighted random sampling on our training data based on
the different class values we have to predict. We use a factor of 50,
meaning the rarest elements will, on average, be sampled only 50 times
less than the most common ones. The sampling factor used for each group
is then \(\frac{50}{count + 50}\), instead of \(\frac{1}{count}\) where
count is the number of cells in each group.

\subsubsection{The classification task}\label{the-classification-task}

We perform label prediction during pretraining for different classes,
currently: cell type, disease, sequencer, ethnicity, sex, and organism.
Due to issues in the ontologies, we have omitted tissue type and age
classes.

Due to the hierarchical structure of the prediction, we also created a
hierarchical loss. Here, we compute the loss regularly when the label is
a leaf label. Otherwise, we replace all associated leaf labels to the
given label by the log-sum-exp, such that for a cell label, the loss is:

\begin{equation}
Loss_{classification} = CE(\sigma(\overline{\mathbf{c}},\mathbf{c}))
\label{eq:class_loss}
\end{equation}

with:

\begin{equation}
\overline{\mathbf{c}} = \left\{ \begin{array}{r}
\widehat{\mathbf{c}} \quad \text{if } \left\{ i | c_{i} = 1 \right\} \subseteq T \\
LSE\left( {\widehat{\mathbf{c}}}_{d} \right)||{\widehat{\mathbf{c}}}_{\sim d} \quad \text{else}
\end{array} \right.
\label{eq:c_bar}
\end{equation}

where:

\begin{itemize}
\item
  \(\widehat{\mathbf{c}}\) is the predicted vector with dimension equal
  to the number of leaf labels
\item
  \(\mathbf{T}\) being the set of label indices marking the labels that
  are leaf labels.
\item
  \({\widehat{\mathbf{c}}}_{d}\  = \ \{\widehat{c_{i}},\ \forall\ i\  \in \ T\}\)
  all the values in vector \(\widehat{\mathbf{c}}\) whose indices are in
  T. Same for \(\mathbf{c}\).
\item
  \({\widehat{\mathbf{c}}}_{\sim d}\  = \ \{\widehat{c_{i}},\ \forall\ i\  \notin \ T\}\)
  all the values in vector \(\widehat{\mathbf{c}}\) whose indices are
  not in T. Same for \(\mathbf{c}\).
\item
  LSE is the log-sum-exp operation
\end{itemize}

The CE (cross-entropy) is defined as:

\begin{equation}
CE(\mathbf{p},\mathbf{q}) = - \sum_{u}{q_{u}\log(p_{u})}
\label{eq:cross_entropy}
\end{equation}

And the LSE (log-sum-exp) is defined as

\begin{equation}
LSE(X) = \log\left(\sum_{p \in X}e^{p}\right)
\label{eq:lse}
\end{equation}

This loss allows the classifier to learn even in cases where the labels
can be of varying coarseness without the coarseness of some labels
impacting the ability of the model to predict the true fine-grained
labels (see Supplementary Figure \ref{fig-s14-hierarchical-classifier})

The loss is hierarchical for the classes: cell type, disease, sequencer,
ethnicity; the labels follow a hierarchy defined by (Cell Ontology,
MONDO, EFO, HANCESTRO), respectively.

We do not compute the loss for cells where a class has an unknown label.
We perform these classification tasks in one pass, using the embeddings
generated directly from the downsampled expression profile.

\subsubsection{The denoising task}\label{the-denoising-task}

Similarly to ADImpute, we expect a good gene network to help denoise an
expression profile by leveraging a sparse and reliable set of known
gene-gene interactions. In addition, we expect a good cell model to help
embed and reconstruct an expression profile by leveraging the
regularities of modules and communities within its network.

We view denoising similarly to upsampling, and inversely, we view adding
noise as downsampling a cell profile.

Noise is similar to downsampling because of the distribution we are
working with. Note that contrary to vision tasks (e.g. diffusion
models), where additive Gaussian noise is added, in the context of
expression data, where the distribution is often seen as a Poisson, NB,
or ZINB, the data is already noisy, and the more counts are sampled, the
less noise. No information is similar to not sampling data.

We downsample an expression profile using a zero-inflated Poisson model
of the data. With this formulation, on average, half of the counts to be
dropped are dropped by randomly removing a number of reads per gene,
given by sampling from a Poisson whose lambda parameter is proportional
to the number of counts in that gene. The remaining half of the counts
to be dropped are dropped by randomly setting some genes to 0, i.e. a
complete dropout of that gene. It is to be noted that with this
definition of downsampling, the exact average amount of counts dropped
for both parts depends slightly on the dropout \emph{r.} During our
pretraining, \emph{r} is set to 0.6, meaning, on average, 60\% of the
transcript counts are dropped per cell.

Let \(\mathbf{x}_{\mathbf{i}}\) be the gene expression vector of cell i
with dimensions \(n_{genes}\); we create a downsampled \emph{version} by
doing

\begin{equation}
{\widehat{\mathbf{x}}}_{\mathbf{i}} = \max((\mathbf{x}_{\mathbf{i}} - \mathbf{p}_{\mathbf{i}}) \cdot \mathbf{\pi}_{\mathbf{i}}, 0)
\label{eq:downsample}
\end{equation}

with:

\begin{itemize}
\item
  \(\mathbf{p}_{\mathbf{i}}\ \sim\ Poisson(\mathbf{x}_{\mathbf{i}}\  \times r \times 0.55)\)
  a vector of size \(n_{genes}\) where the poisson is samples for each
  element \(\mathbf{x}_{\mathbf{i}}\) of x
\item
  \(\mathbf{\pi}_{\mathbf{i}}\  = \ I(u \geq r \times 0.55)\) a vector
  of size \(n_{genes}\) , the binary mask vector indicating non-dropout
  genes.
\item
  \(\mathbf{u}_{\mathbf{i}}\ \sim\ Uniform(0,1)\), a vector of size
  \(n_{genes}\). of random values drawn from a uniform distribution.
\item
  \(\cdot\) denotes the element-wise multiplication.
\item
  \emph{r} being the dropout amount. We scale it by a tuning
  hyperparameter of 0.55 instead of 0.5 for numerical reasons.
\end{itemize}

The goal of the model is then using
\({\widehat{\mathbf{x}}}_{\mathbf{i}}\) as an input to output the
parameters
\(\mathbf{\mu}_{\mathbf{i}}\ ,\ \mathbf{\theta}_{\mathbf{i}}\ ,\ \mathbf{\pi}_{\mathbf{i}}\)
of a \emph{ZINB} distribution of the true profile
\(\mathbf{x}_{\mathbf{i}}\) \emph{,} all vectors of size \(n_{genes}\).
The contribution of cell i to the loss is then computed as the negative
log-likelihood of the count data given the distribution parameters being
generated by the model

\begin{equation}
Loss_{denoising} = Loss_{ZINB} = - \frac{1}{n_{gene}m}\sum_{i = 0,j = 0}^{n_{gene},m}{\log(L(x_{i,j}| \mu_{i,j}, \theta_{i,j}, \pi_{i,j}))}
\label{eq:denoising_loss}
\end{equation}

where \(n_{gene}\) is the size of the expression profile
\(\mathbf{x}_{\mathbf{i}}\) , m is the size of the minibatch and

\begin{equation}
L\left( x | \mu,\theta,\pi \right) = \left\{ \begin{array}{r}
\frac{\pi}{\pi - \theta \cdot (\log(\theta) - \log(\theta + \mu))} \quad \text{if } x = 0 \\
\frac{\left(\frac{\mu}{\theta + \mu}\right)^{x} \cdot \Gamma(x + \theta) \cdot \sigma(-\pi)}{\exp(\pi) \cdot \left( \frac{\mu}{\theta + \mu} \right)^{\theta} \cdot \Gamma(\theta) \cdot \Gamma(x + 1)} \quad \text{if } x > 0
\end{array} \right.
\label{eq:likelihood}
\end{equation}

with \(\sigma\) the sigmoid function.

We show that models trained with such a framework perform better than
regular MSE-trained models (see Supplementary Table \ref{table-s3-ablation-study-and-impact-on-performance-across-tasks}), for which one only outputs
one value instead of three, directly representing the
data's log-transformed count. In this case, the loss is
the mean squared error between the predicted and true count values.

scPRINT effectively lets the user choose between the three formulations:
\emph{ZINB} with a \emph{ZINB} loss, NB with an NB loss, and direct
log-transformed count reconstruction with an \emph{MSE} loss.

However, we have noted that the \emph{NB} and \emph{ZINB} loss still
have some notable issues. They can easily overflow, especially when
working with lower precision systems (like fp16, bf16, etc). These
losses are also proportional to the total expression count, meaning
cells with higher expression will have a higher loss on average. It also
appears that the log-likelihood cannot go below \textasciitilde1.1 loss
on average and plateaus quickly. This makes evaluation of the loss less
practical when comparing models. Finally, this minimal loss also depends
on the total number of zeros in the true expression dataset, as the
zero-inflation part of the loss converges smoothly to 0.

\subsubsection{The bottleneck learning
task}\label{the-bottleneck-learning-task}

Bottleneck learning is a method that drives the model to generate a cell
expression profile only from its embedding. Cell-embedding which can be
passed again to that same model without the gene expression information,
such that from the cell-embedding only, scPRINT can re-generate the
cell's expression profile. The model thus finds the best compression of
the cell's expression according to the information-theoretic theorem by
Tishbi et al. .

While many transformer models and Geneformer directly use the average of
gene embeddings to generate a cell embedding, this will likely squash
the expression information.\\
scGPT used another methodology (called MVC) to generate an embedding
vector such that

\begin{equation}
x_{i,j} = \mathbf{e}_{\mathbf{i}} \odot \mathbf{g}_{\mathbf{j}}
\label{eq:scgpt_mvc}
\end{equation}

where \(x_{i,j}\) is the expression of gene j in cell i, and \(\odot\)
is the dot product. For each gene embedding \(\mathbf{g}_{\mathbf{j}}\)
, the embedding only contains information about the gene name, not gene
expression. Regular MSE on each \(x_{i,j}\) is then used as the training
loss.

This pushes the cell embedding \(\mathbf{e}_{\mathbf{i}}\) to contain
all the expression information of the cell i.

This is less computationally intensive to train than our bottleneck
learning method. However, we have noticed poorer reconstruction through
this methodology than ours (see Supplementary Table \ref{table-s3-ablation-study-and-impact-on-performance-across-tasks}).

In our case, we consider that our model scPRINT can act as two parts of
an autoencoder. The encoding part is when we give scPRINT the expression
profile of a cell and retrieve a set of disentangled cell embeddings
(see the \hyperref[class-decoder]{Class decoder} section of the
methods). The decoder part is when we provide scPRINT only the gene
labels without their corresponding expression values and the
disentangled cell embedding in place of the empty placeholder embeddings
(see Supplementary Figure \ref{fig-s15-detailed-representation-of-the-bottleneck-learning-procedure}).

This means the encoder is considered as

\begin{equation}
\mathbf{e}_{\mathbf{A,i}} = scPRINT([\mathbf{g}_{\mathbf{O}} + \mathbf{e}_{\mathbf{0,i}} + \mathbf{l}_{\mathbf{0}}, \mathbf{g}_{\mathbf{1}} + \mathbf{e}_{\mathbf{1,i}} + \mathbf{l}_{\mathbf{1}}, ..., \mathbf{p}_{\mathbf{A}}])
\label{eq:encoder}
\end{equation}

where \(\mathbf{e}_{A,i}\) is the output embedding of the placeholder
embedding token A for the cell i (in our case, we use multiple (default,
totalcount, cell\_type, disease, sex, organism, ethnicity, sequencer).
Then the decoder is defined as

\begin{equation}
\mathbf{\mu}_{\mathbf{i}},\mathbf{\theta}_{\mathbf{i}},\mathbf{\pi}_{\mathbf{i}} = scPRINT([\mathbf{g}_{\mathbf{O}} + \mathbf{l}_{\mathbf{0}}, \mathbf{g}_{\mathbf{1}} + \mathbf{l}_{\mathbf{1}}, ...], \mathbf{e}_{\mathbf{0,i}}, \mathbf{e}_{\mathbf{1,i}}, ..., \mathbf{e}_{\mathbf{t,i}})
\label{eq:decoder}
\end{equation}

With
\(\mathbf{\mu}_{\mathbf{i}}\ ,\ \mathbf{\theta}_{\mathbf{i\ }},\ \mathbf{\pi}_{\mathbf{i}}\)
vectors of size \(n_{genes}\). Finally, the loss is given by the ZINB
loss:

\begin{equation}
Loss_{bottleneck} = \sum_{i = 0}^{m}{Loss_{ZINB}(\mathbf{x}_{\mathbf{i}} | \mathbf{\mu}_{\mathbf{i}}, \mathbf{\theta}_{\mathbf{i}}, \mathbf{\pi}_{\mathbf{i}})}
\label{eq:bottleneck_loss}
\end{equation}

where \(\mathbf{x}_{\mathbf{i}}\) is the cell i expression profile and
\emph{m} the minibatch size.

Implementing a set of disentangled embeddings is not straightforward. In
our case, we push the embeddings to be as different from one another as
possible with a contrastive loss defined as

\begin{equation}
Loss_{contrastive} = \frac{1}{m^{2}}\sum_{i = 1}^{m}{\sum_{i'}^{m}{1 - \cos(\mathbf{e}_{\mathbf{i}},\mathbf{e}_{\mathbf{i'}})}}
\label{eq:contrastive_loss}
\end{equation}

where \(\mathbf{e}_{\mathbf{i}}\) and \(\mathbf{e}_{\mathbf{i'}}\) are
the cell embeddings, \emph{m} is the minibatch size, and \emph{cos}
denotes the cosine similarity. This pushes each embedding to represent
the correct information using the classifiers. However, more is needed
to remove all the batch effects or entirely prevent information leakage
across embeddings.

Finally, we have also used the classifier output logits as cell
embeddings. This works particularly well for cell type, disease, or
sequencer classes containing many labels. It has been shown that
classifier logit outputs behave similarly to
embeddings and, in our case, offer an even better
removal of the batch effects (See Supplementary Figure \ref{fig-s7-full-scib-batch-correction-scores}).

For the bottleneck loss, we directly reconstruct expression using the
cell embeddings generated from the noisy, downsampled expression profile
of the denoising process, doing the entire process in one single pass.
We sum all the losses without scaling them:

\begin{equation}
Loss = Loss_{contrastive} + Loss_{bottleneck} + Loss_{denoising} + Loss_{class}
\label{eq:total_loss}
\end{equation}

\subsection{scDataloader}\label{scdataloader}

Parallel to this work, we worked with Lamin.ai to develop a dataloader
for large cell atlases, described and benchmarked in Rybakov et
al.. One key advantage of this dataloader is its
ability to perform weighted random sampling on hundreds of millions of
cells without being a bottleneck during pretraining.
scDataloader samples cells amongst the 800+
datasets of cellxgene's mid-2023 release, using the cell labels to
inform how rare the specific combination of labels is.

From this, the dataloader produces a cell sampling weight, rescaled with
a hyperparameter. The dataloader will sample, with replacement, more
consistently rare cell types than more common ones.

We have produced an additional wrapper package around the laminDB
``mapped-dataset'' called scDataloader. scDataloader works with lamin.ai
but can also interface with scVI and AnnData formats to enable
downloading, preprocessing, and QC of large single-cell databases and
datasets. It is very flexible and can represent expression data in the
formats used by scPRINT, scGPT, and Geneformer. It also implements a
lightning datamodule scheme and command line interfaces for quick setup
(see Supplementary Figure \ref{fig-s16-schematic-representation-of-our-dataloader}).

Overall, we preprocess each of the 1200 datasets in cellxgene by only
keeping primary cells from either humans or mice and dropping all the
spatial omics datasets. Spatial omics are not true single-cell assays,
and we decided for now not to include them. We also drop any cells with
less than 200 expressed genes. Finally, we drop any resulting dataset
smaller than 100 cells, with less than 10,000 genes, or from which more
than 95\% of the cells have been removed. This results in a new database
of 54,084,961 cells and 548 datasets.

We believe that the weighted random sampling strategy allowed our
pre-training to be much faster by creating more diverse minibatches.

\subsection{Extracting meta-cell gene networks from attention matrices
in
scPRINT}\label{extracting-meta-cell-gene-networks-from-attention-matrices-in-scprint}

Transformers compute multiple attention matrices per layer, called
attention heads. This is done by splitting the generated
\emph{\textbf{K}, \textbf{Q}}, and \emph{\textbf{V}} embedding into
\emph{m} sub-embeddings, thus defining \emph{m} attention heads. Each
attention head computes the attention matrix via the equation:

\begin{equation}
\text{softmax}\left(\frac{\mathbf{QK}^{T}}{\sqrt{d_{k}}}\right)
\label{eq:attention}
\end{equation}

However, we would want to aggregate those over multiple cells from a
similar cell state to increase the signal obtained from only one cell.
We are doing so by averaging the Keys and Queries embeddings over the
set of cells \(U\) passed to the model:

\begin{equation}
\text{softmax}\left(\frac{mean_{U}(\mathbf{Q}) \cdot mean_{U}(\mathbf{K})^{T}}{\sqrt{d_{k}}}\right)
\label{eq:meta_attention}
\end{equation}

By doing this, the attention matrix behaves as if each query vector for
cell i was ``looking'' across the key vectors of all the cells in U.

The resulting object is a row-wise normalized \emph{n*n} matrix, where
\emph{n} is the size of the input context (i.e. the number of genes
passed to the model). However, we also include the possibility to
generate large matrices and gene networks, referred to as genome-wide
gene networks. We take the average over different sets of expressed
genes for each cell in the set U. This allows us to compute a
genome-wide attention matrix while only doing forward passes on smaller
subsets of the genome per cell.

\subsection{Heads selection}\label{heads-selection}

With scPRINT, we present a method to select heads based on some
available ground truth data. This is inspired by the ESM2
paper and uses a somewhat similar method. Using all
the available attention matrices from all of the model's heads, we use a
linear classifier RidgeClassifier from scikit-learn
(with an L2 penalty set to 1, a positivity constraint on the
coefficients, and without an intercept) to classify the ground truth's
edges based on a combination of each head. The classifier converts the
target values into \{-1, 1\} equals to \{no connections, connections\}
and then treats the problem as a regression task with mean squared
error.

Instead of taking the classifier's output, we use the average of the
subset of heads associated with a non-zero coefficient in the
classifier, without weighting them. Thus, the classifier only serves as
a means to select the heads with relevant information in predicting a
ground truth of interest and decreases the possibility of overfitting
(see Figure 1C).

\subsection{\texorpdfstring{Normalization and network interpretation
}{Normalization and network interpretation }}\label{normalization-and-network-interpretation}

In scPRINT and scGPT, the attention matrix is normalized via the softmax
function over the query (i.e., row) dimensions. This means that all row
elements sum up to 1 or that the same mass flows from each network
component. This rescaling is essential as it corrects that some row
element scales can be much higher than others in the attention matrix.
Similarly, in regularized models like GENIE3, only a small set of genes
are connected for each gene in the matrix, meaning all genes have
directed edges toward a small subset of genes. Thus, our interpretation
is that the row elements are the targets in our network, each connected
to a small subset of genes. The column elements are thus the regulators
and can regulate many / most genes in the network.

For biological ground truths like MCalla et al. and gwps, which fit this
assumption of highly connected regulators and sparsely regulated
targets, we directly compare them to the inferred network. Tables S12
and S13 show that this performs better than taking the opposite view by
transposing the inferred networks.

This assumption is challenged for Omnipath, which has most of its
elements connected to a sparse set of other elements (see Supplementary Figure\ref{fig-s3-distribution-of-connection-amongst-the-three-ground-truths}). Due to the sparsity of connections for regulators (i.e., sources)
in the ground truth network and the large number of regulators (8000+),
the methods are challenged and perform much better when taking the
transpose of their network and matching the regulators to the sources
and sources to regulators.

\subsection{Simulated datasets, BoolODE and
Sergio}\label{simulated-datasets-boolode-and-sergio}

BoolODE is a method to generate count data via a stochastic differential
equation applied over a user-defined Boolean network. It was used and
developed as part of the BEELINE benchmark algorithm, which was created
as an improvement over the GeneNetWeaver algorithm. However, this model
is still very simple compared to cell biology. Due to its computational
complexity, it can only model up to a couple hundred gene relationships
over a few dozen genes.

Sergio, a slightly more recent ODE model marks an
improvement over BoolODE on the size of the networks it can simulate (up
to a thousand genes) and its similarity to scRNAseq data.

Indeed, Sergio's simulated data is not similar to real
expression data. This means that the biases that Transformer models
learn should not help them predict Sergio's data.
Correlation and regression-based methods do not have biases. They are
therefore expected and have traditionally shown better performance on
these benchmarks.

We generated the Sergio ground truth network and simulated single cell
expression by using the notebook:
\url{https://github.com/g-torr/SERGIO/blob/v2/minimal_example.ipynb}
from the repository: \url{https://github.com/g-torr/SERGIO} which
present some debugs and improvements to the initial repository:
\url{https://github.com/PayamDiba/SERGIO}. Indeed only this fork of the
initial Sergio repository led us to successfully generate a network.\\
\strut \\
We used RegNetwork as input and simulated 1000 cells
from its 3546 connections over 813 genes with default parameters from
the notebook.

\subsection{BenGRN and gene network
metrics}\label{bengrn-and-gene-network-metrics}

We use the packages benGRN and GRnnData released with this manuscript to
work With Gene networks and perform our benchmarks.

Our three main metrics are EPR, AUPRC, and enrichment. They all take
advantage of the fact that the predictions are generated as scores over
edges between nodes:

\begin{itemize}
\item
  We have computed the Early Precision Ratio (EPR) as the diagnostic
  odds ratio: (TP x TN) / (FP x FN) at the cutoff of the scores giving
  \emph{K} positive predictions, where \emph{K} is the number of
  positive elements in the ground truth.\\
  In this context, 1 is a random prediction, and inf is a perfect
  prediction; values below one mean that inverting the predictor would
  provide better results.
\item
  Area Under the Precision-Recall Curve (AUPRC) is the area (computed
  with the composite trapezoidal rule) under the curve defined by the
  precision (\emph{PR = TP / (TP + FP})) and recall (\emph{RE = TP / (TP
  + FN})) where \emph{TP} is the number of true positives, FP is the
  number of false positives, and \emph{FN} is the number of false
  negatives. This curve is obtained through a range of cutoffs going
  from 0 predicted positives to all predicted positives. Here, we
  compute a version of the AUPRC where the floor of the area is not
  given by the Precision=0 line but by the line of the prevalence of the
  positive class. Moreover, we do not interpolate the curve between the
  last recall value and the perfect recall: 1. We do this to properly
  compare AUPRC values across benchmarks and models. Random precision
  values are given in the supplementary data.
\item
  Enrichment is computed using the prerank
  methodology, where, given an ordered set of genes,
  it is computed by:

  \begin{itemize}
  \item
    1. Summing all scores of edges of the matrix row-wise. (Target -
    Hub) Or
  \item
    2. Summing all scores of edges of the matrix column-wise.
    (Regulators - Hub) Or
  \item
    3. Computing the eigenvector centrality of nodes in the
    graph using NetworkX's implementation.
    Prerank's background comprises all the genes in the set
    (centrality).
  \end{itemize}
\end{itemize}

Of note, we did not design an automated method for cell-type enrichment.
Instead, the assessment of whether or not a network is enriched for the
correct cell type is done manually, identifying cell type names in the
top 10 cell types listed in the enrichment results of the network.

\subsection{Other evaluation metrics}\label{other-evaluation-metrics}

All evaluation metrics from the section "%\href[scprintcompet]{
scPRINT is competitive on tasks orthogonal to
GN inference" of the results come from the openproblems benchmark and
are standards in the field.

scIB's batch correction score is an average of the avgBatch score and
the avgBio score, which are themselves averaged over many scores.
Details of each value are available in our package's notebooks.

\begin{itemize}
\item
  scIB avgBio is a combination of label-based and label-free metrics
  using for example: the Adjusted Rand Index (ARI)
  and the Normalized Mutual Information (NMI) on
  clusters computed from the K-Nearest Neighbor graph. Other scores are
  used, some using the conservation of trajectories and of the cell
  cycle variance, and some on the rare cell population conservation,
  overlap of highly variable genes (see scIB), and
  more.
\item
  scIB avgBatch is a similar combination of label-based and label-free
  metrics, using, for example, the average connectivity across clusters
  of different batches: ASW, the graph integration
  local inverse Simpson's Index: graph iLISI, the
  k-nearest-neighbor Batch Effect Test (kBET), and
  more.
\end{itemize}

Finally, we also use two metrics in our classification task:

\begin{itemize}
\item
  Macro-F1: also called macro-average, is the average of the F1 score
  across each class in a multi-class task. Where the F1 score is:
  \(2 \times \ \frac{PR*RE}{PR + RE}\).
\end{itemize}

\begin{itemize}
\item
  Accuracy: the accuracy is computed as
  \(\frac{TP\  + \ TN}{TP + TN\  + FN + FP}\)
\end{itemize}

\subsection{Denoising Benchmarks}\label{denoising-benchmarks}

To validate the denoising ability of scPRINT,
MAGIC, and
KNNsmoothing2, our test function, available in the
scPRINT package, uses a representative subset of 10,000 cells of each
dataset to generate the denoised expression over the 5000 most variable
genes in this dataset.

Before that, counts are removed from the dataset following the same
procedure as done for scPRINT's pretraining (see
\hyperref[the-denoising-task]{The denoising task} section of the
methods).

For each cell, we compare the denoised and un-denoised profiles to the
true profile (e.g. before denoising). We compute the Spearman's
correlation over the genes initially expressed in the cell, taking the
average across all cells. We do not use the unexpressed genes as we are
working with a dataset with high dropout and expect that a good denoiser
will set genes that are 0 in the profile with some value. We notice that
this improves the score of all denoising methods and makes more sense
given the data.

For the rare cell population test, we keep everything similar but
compute only the Spearman correlation over a rare cell population in the
dataset.

We run KNNsmoothing2 with default parameters and a K of 10. We run MAGIC
using the Scanpy implementation with default parameters and the
approximate solver for computational speed. When computing KNNsmoothing2
or MAGIC over a small set of cells we use a K of 5 for the nearest
neighbors.

\subsection{Fine-tuning}\label{fine-tuning}

Contrary to most other foundation models for scRNAseq, we do not
finetune scPRINT at any moment in our benchmark and all results are
provided for the pre-trained model only.

While we haven't assessed fine-tuning we believe this is an important
feature of foundation models and release various scPRINT models so that
they can be re-trained, fine-tuned, and modified by the community for
novel tasks or to improve its performance on the tasks we have
presented.

\subsection{State-of-the-art methods used in
benchmarking}\label{state-of-the-art-methods-used-in-benchmarking}

All methods presented here generate networks from their input data.
Given gene-level expression data, they will generate gene-networks.
Without additional information, no method can distinguish the type of
molecular interactions that underpin their predicted network edges.

\subsubsection{Gene network inference with an ensemble of trees
(GENIE3)}\label{gene-network-inference-with-an-ensemble-of-trees-genie3}

Developed originally for bulk transcriptional data, \emph{GENIE3}
computes the regulatory network for each gene independently. It uses a
random forest, a weak learner ensemble method, to predict the expression
profile of each target gene from profiles of all the other genes. The
weight of an interaction comes from the feature importance value of an
input gene in the predictor for a target gene's expression pattern.
Aggregating these weighted interactions over all the genes yields the
regulatory network. This method was the top performer in the DREAM4 in
silico network challenge (multifactorial subchallenge).

\emph{GENIE3} can be seen as a generalization of correlation-based
methods for inferring gene networks. Instead of looking at genes that
correlate most with another gene, GENIE3 finds how to combine a set of
correlated genes to get an even better correlation. We run GENIE3 on raw
counts as it is said from both the BEELINE benchmark and the R package
vignette that GENIE3 can be run on either log normalized or raw count
data and that while it will change the results, there are no preferred
methods. This is something we have also noted in our trials.\\
\strut \\
We use all default parameters and choose 100 trees for computational
feasibility reasons. We compute the networks on the same set of cells
and genes as the other methods.

We also use a TF-gene only version of the method where the regression is
performed only using the expressed transcription factors instead of all
expressed genes as input. This is the most used version of \emph{GENIE3}
and is much faster.

\subsubsection{DeepSEM}\label{deepsem}

DeepSEM is an autoencoder model made for gene network inference. It
learns to decompose a set of cells as a set of embedding and an
adjacency matrix (i.e., a gene network). The formula of the VAE then
becomes:
\(\mathbf{X} = f_{1}({(\mathbf{I} - \mathbf{W}^{\top})}^{- 1}\mathbf{Z})\),
for the decoder and
\(\mathbf{Z} = {(\mathbf{I} - \mathbf{W}^{\top})}^{- 1}f_{2}(\mathbf{X})\)
for the encoder, where \(\mathbf{X}\) is the expression data,
\(\mathbf{Z}\) is the embedding dimension, \(\mathbf{W}\) is the
adjacency matrix, \(\mathbf{I}\) the identity, and \(f_{1},f_{2}\) are
MLPs.

We preprocess the anndata by normalizing gene expression to 10,000
genes, applying a logp1 transformation, and then computing the z-score
per gene, as explained in the associated research paper.\\
We use DeepSEM with default parameters and on the same set of cells and
genes as the other methods. We use the DeepSEM-provided functions for
loading and parsing Anndatas.

\subsubsection{Single-cell generative pretraining transformer
(scGPT)}\label{single-cell-generative-pretraining-transformer-scgpt}

scGPT is a transformer-based model of roughly 100M parameters,
pre-trained with a generative process similar to Language models. scGPT
proposes to build similarity networks based on the output gene
embeddings of the model but also based on its attention matrices. It
computes networks as the difference between the rank-normalized version
of the average attention matrix in a baseline expression profile vs a
perturbed one in perturb-seq data. The attention matrix is the average
of attention matrices over the heads of the last layer and over the
cells given to the model.

We run scGPT following the examples given in their
``Tutorial\_Attention\_GRN.ipynb'' notebook.

We use the ``scGPT\_human/best\_model.pt'' from the list of available
models with default parameters. All runs are in our fork:
``https://github.com/jkobject/scGPT'' in the ``mytests/'' folder.
Similarly, we take the mean over cells and over the heads of the last
layer. We compute softmax similarly to the attention computation but
without applying the rescaling factor \(\sqrt{d_{k}}\) . We finally drop
the first element corresponding to the cell embedding token.

We extract cell embeddings from scGPT by directly using the cell
embedding token of the model without fine-tuning it on a batch
correction task. This is done in order to compare it to scPRINT which is
itself not fine-tuned. We compute the networks on the same set of cells
and genes as the other methods.

\subsubsection{Geneformer}\label{geneformer}

Geneformer is a BERT model. Gene expression data is transformed into a
sentence or genes ordered by their scaled expression. It is trained with
mask language modeling and contains somewhere around 80M parameters. We
use the new versions of 2024 Geneformer models
trained on 100M cells (2x more than scPRINT). We follow the
preprocessing and inference scripts used in the geneformer huggingface
repository and notebooks:
\url{https://huggingface.co/ctheodoris/Geneformer/tree/main}. Our
inference script updates to extract gene networks from Geneformer are
available in our scPRINT repository:
\url{https://github.com/cantinilab/scPRINT/tree/dev/tools}.

We extract gene networks from Geneformer using the mean of all attention
heads per cell. Since Geneformer only uses expressed genes in a cell, we
have to map the attention matrices back to the full network size before
computing its average over cells, taking into account the NaN values. We
compute the networks on the same set of cells and genes as the other
methods.

We extract a cell embedding from Geneformer using the cell embedding
from the ``gf-12L-95M-i4096\_MTLCellClassifier\_CELLxGENE\_240522''
model that has been fine-tuned on predicting the cell labels of
cellxgene datasets.

\subsubsection{scFoundation}\label{scfoundation}

scFoundation is a foundation model for single-cell RNAseq based on the
xtrimogene architecture. It was built by the Biomap
company. It is able to work on the full genome sequence of transcripts
for each cell by considering the high number of zeros and embedding them
separately. The tool is aimed at performing a range of tasks, such as
denoising, embedding, and predicting perturbation response. It has been
trained with a mixed masking and denoising pre-training. However, we
could not compare scFoundation to scPRINT and MAGIC on the denoising
benchmark, as scFoundation's denoising only happens at the level of the
cell embedding at inference time.

We could not validate scFoundation on our Gene network inference
benchmark as extracting a network from the attention matrices was much
more complex due to the xtrimogene architecture. scFoundation mentions
the generation of gene modules using clustering of its output gene
embeddings. It also mentions the interference of gene networks. However,
it is achieved using RcisTarget, a prior gene network
based on motif analysis. This approach is not comparable to the gene
networks generated by scPrint, Geneformer, and scGPT. Indeed, RcisTarget
could be applied to every model we have benchmarked and would prevent us
from doing an unbiased benchmark. Neither our approach nor Hao et al.'s
could extract gene networks directly from scFoundation. It is being left
to further investigations.

For batch effect correction, we use scFoundation with default parameters
and follow the steps for cell embedding in the ``model/README.md'' file
in their GitHub repository:
\href{https://github.com/biomap-research/scFoundation/}{https://github.com/biomap-research/scFoundation}.
However, we give scFoundation single cell profiles of the 5000 most
variable genes in each dataset. This is because we could not run
scFoundation on genome-wide expression profiles with our GPU. We then
apply a PCA to the output embedding to reduce the dimensionality from
3224 to 512. This is because the initial dimension was too high for scIB
to compute a score from on our machine (40CPU Intel Xeon, 32GB RAM +
64GB SWAP, GPU NVIDIA A4500 with 20GB of memory).

\subsubsection{Marker-based cell type prediction with CellTypist}\label{marker-based-cell-type-prediction-with-celltypist}

To showcase the novel ability of scPRINT to perform zero-shot prediction of cell type labels, we use the CellTypist method, which similarly performs de-novo prediction of cell type labels given its precomputed databases of cell type markers.

CellTypist works by mapping cell gene expression to genes known to be specifically expressed in combination in a cell type. Thus, it predicts cell type from these marker genes.

We use it with default parameters on the normalized and log-transformed counts over the full set of genes in the dataset. We use the `Adult\_Human\_PancreaticIslet' database, which contains markers for 14 cell types and overlaps with only four of the cell types in the dataset.

We decided to still use it as is to showcase the marker-based method's inability to recover the full set of cells and the tradeoff between the number of cell types and accuracy.

Fortunately, these four cell types (A, B, D, PP) represent 70\% of the dataset. With its current database, CellTypist can only reach a maximum accuracy of 70\%. Even when taking this into account, CellTypist only overperforms scPRINT on the accuracy metric and by roughly 9 points.

\subsubsection{Classification benchmark and associated
methods}\label{classification-benchmark-and-associated-methods}

Our classification benchmark is run using following the openproblems benchmark. It uses the same input, output data, and metric. It also similarly splits the train-test by batch and preprocesses the expression matrix to what is presented in the open problem benchmarks.

For this task, methods can access the full set of genes by default. scPRINT will use its random sampling of genes approach with a context of 4000 genes. Classifiers like logistic regression and xgboost were run according to the openproblem process, using the 25 principal components of the count normalized, logp1 transformed expression data. CellTypist was run on the normalized and logp1-transformed cell expression profile.

\subsection{Ground truth preparation}\label{ground-truth-preparation}

\subsubsection{McCalla et al.}\label{mccalla-et-al.}

For the MCalla et al. dataset, we downloaded the data from the supplementary datasets of \href{https://www.biorxiv.org/content/10.1101/2021.06.01.446671v2.supplementary-material?versioned=true}{their paper} . After undoing the logp1 transform, we re-generate the true count expression matrix from the normalized one by dividing the expression of each cell by the smallest value in its expression profile. This fully recovered the true counts, all values being integers. For the additional human dataset we used, we downloaded it from the \href{https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-36552/downloads}{gene expression atlas database}.

We used the intersection (gold standard) ground truth dataset for both human and mouse, converting this list of sources to target genes into a directed binary network.

\subsubsection{Omnipath}\label{omnipath}

We generate the Omnipath network using all the interactions from the Omnipath Python package, excluding small molecules, lncRNAs, and any element without a unique HGNC symbol. We then transform it into a directed binary network of source to target. These interactions are extracted from the literature and represent mainly TF to gene connections as well as many protein-protein interaction connections and a small number of other connections known from the literature like RNA-RNA interactions, protein-RNA interactions, and more. All interactions are mapped back to their gene IDs, generating a gene-gene network encompassing the various interactions the genes and their molecular products can have.

\subsubsection{Gene networks from genome-wide perturb-seq}\label{gene-networks-from-genome-wide-perturb-seq}

We created a gene network from the genome-wide perturb-seq dataset using the supplementary matrix containing the results of differential expression in the dataset. This matrix represents the multiple hypothesis testing corrected p-values of a differential expression test of cells with KO of gene A compared to the baseline cell expression. This is available for all 8000+ expressed genes in the K562 cell line. We used a cutoff of 0.05 on these values to define the directed binary connection between genes.

This effectively gives a gene x gene-directed binary graph that tells if a statistically significant connection exists from the source \({gene}_{A}\) to the target \({gene}_{B}\) according to genome-wide perturb-seq.

For all ground truths, download, preprocessing, and extraction of the network and expression data are available in the BenGRN package.

\subsection{\texorpdfstring{Details on the Benign Prostatic Hyperplasia analysis}{Details on the Benign Prostatic Hyperplasia analysis }}\label{details-on-the-benign-prostatic-hyperplasia-analysis}

We download our dataset from cellxgene under the reference: \emph{574e9f9e-f8b4-41ef-bf19-89a9964fd9c7}.

We preprocess the dataset using scDataloader's preprocessing function. We generate embedding and classification using 3000 expressed genes in each cell. Similarly to pretraining, we take 3000 randomly expressed genes; if less than 3000 are expressed, we complete with randomly selected unexpressed genes. We display embeddings generated using the cell type classifier logits (see section \hyperref[the-classification-task]{The classification task} in methods)

We use the Scanpy toolkit to generate our Umap plots directly from the embeddings, as well as our differential expression results and our clusters. We define the clusters using the Louvain algorithm with 10 k-nearest-neighbors and a resolution of 1. We perform denoising on 5000 genes per cell selected similarly to the embedding and classification part. We use the 4000 most variable genes in each cell type to generate our gene networks in the BPH and normal fibroblasts.

On the gene networks, we perform gene set enrichment with the Enrichr method on the GO\_MF\_2023 gene sets. For community detection, we use the Louvain algorithm with parameter 1.5. We perform analysis only on the communities with between 200 and 20 genes. (4 and 5 in the BPH-associated fibroblasts, 3 and 4 in the normal fibroblasts)

All analysis and results are available in the \emph{cancer\_usecase\_1} and \emph{cancer\_usecase\_2} notebooks.

\subsection{Negative Binomial to Poisson
relationship}\label{negative-binomial-to-poisson-relationship}

As explained in \hyperref[the-denoising-task]{The denoising task} and \hyperref[expression-decoder]{Expression decoder} section of the methods, in our model, we have used the ZINB as our loss, an extension of the NB distribution to zero-inflated data. 

Moreover, we have also used the zero-inflated Poisson mechanism to downsample the cell expression profiles. These are consistent because we can view the Poisson distribution as a NB without overdispersion. The relationship between \emph{NB} and \emph{Poisson} is given by making the dispersion term go to 0 and the inverse dispersion term \(\theta \rightarrow \infty\). Doing so, the term \(\frac{\theta}{\theta + \mu}\) approaches 1. Thus, the PMF simplifies to:

\begin{equation}
P(X = x) \approx \frac{\Gamma(x + \theta)}{x!\Gamma(\theta)}1^{\theta}\left(\frac{\mu}{\theta + \mu}\right)^{x}
\label{eq:pmf_simplified}
\end{equation}

For large \(\theta\), we use Stirling's approximation of the Gamma function: \(\Gamma(\theta) \approx \sqrt{2\pi\theta}{(\frac{\theta}{e})}^{\theta}\)

we get:

\begin{equation}
\Gamma(x + \theta) \approx \sqrt{2\pi(x + \theta)}\left(\frac{x + \theta}{e}\right)^{x + \theta}
\label{eq:stirling1}
\end{equation}

\begin{equation}
\Gamma(\theta) \approx \sqrt{2\pi\theta}\left(\frac{\theta}{e}\right)^{\theta}
\label{eq:stirling2}
\end{equation}

Simplifying the ratio of the Gamma functions:

\begin{equation}
\frac{\sqrt{2\pi(x + \theta)}\left(\frac{x + \theta}{e}\right)^{x + \theta}}{\sqrt{2\pi\theta}\left(\frac{\theta}{e}\right)^{\theta}} = \sqrt{\frac{x + \theta}{\theta}}\left(\frac{x + \theta}{\theta}\right)^{\theta}\left(\frac{x + \theta}{e}\right)^{x}
\label{eq:gamma_ratio}
\end{equation}

For large \(\theta\), \(\frac{x\  + \ \theta}{\theta}\sim 1\), so: \(\sqrt{\frac{x\  + \ \theta}{\theta}} \approx 1\)

\[{(\frac{\ x\  + \ \theta}{\theta})}^{\theta} \approx \ 1\ \]

Thus, the expression simplifies to:

\begin{equation}
P(X = x) \approx \frac{1}{x!}\left(\frac{\mu}{\theta + \mu}\right)^{x}\left(\frac{\theta + x}{\theta}\right)^{x}
\label{eq:pmf_approx}
\end{equation}

Finally, \({(\frac{x\  + \ \theta}{\theta\  + \ \mu})}^{x} \approx \ 1\ \)for large \(\theta\), so:

\begin{equation}
\lim_{\theta \rightarrow \infty}P(X = x) = \frac{\mu^{x}}{x!}e^{-\mu}
\label{eq:poisson_limit}
\end{equation}

This is the PMF of the Poisson distribution with mean \(\mu\).

\subsection{Data availability}

The model weights are publicly available on \href{https://huggingface.co/jkobject}{Hugging Face}. Pre-training logs to assess the model’s training are available on \href{https://wandb.ai/ml4ig/scprint_scale/reports/scPRINT-trainings--Vmlldzo4ODIxMjgx?accessToken=80metwx7b08hhourotpskdyaxiflq700xzmzymr6scvkp69agybt79l341tv68hp}{Weights and Biases}. The full pre-training dataset is publicly available on CellxGene under its census data release version: LTS 2023-12-15, accessible at \url{https://cellxgene.cziscience.com/}. All other datasets used in this work can be downloaded through their respective public databases via the helper scripts on the scPRINT, BenGRN, GRnnData, and scDataLoader packages. Source data are provided to re-generate the figures. Code to generate the large UMAP of Figure 1 is available as a notebook on GitHub at \url{https://github.com/cantinilab/scPRINT/blob/1.6.4/figures/nice_umap.ipynb}. Code to re-generate the source data is available as notebooks on our \href{https://github.com/cantinilab/scPRINT/tree/1.6.4/}{Github}.

\subsection{Code availability}

The code and notebooks used to develop the model, perform the analyses, and generate results in this study are publicly available and have been deposited in cantinilab/scPRINT at \url{https://github.com/cantinilab/scPRINT} under MIT license. The specific version of the code associated with this publication is archived in the same repository under the tag 1.6.4 and is accessible via \url{https://github.com/cantinilab/scPRINT/tree/1.6.4/} and DOI:\href{https://doi.org/10.5281/zenodo.14749466}{10.5281/zenodo.14749466}.

Additional developed packages for this analysis are defined in the pyproject file and project submodules. They are available on GitHub:

\begin{itemize}
    \item \textbf{GrnnData}: \url{https://github.com/cantinilab/GRnnData}, DOI:\href{https://doi.org/10.5281/zenodo.10573141}{10.5281/zenodo.10573141}
    \item \textbf{BenGRN}: \url{https://github.com/jkobject/benGRN}, DOI:\href{https://doi.org/10.5281/zenodo.10573209}{10.5281/zenodo.10573209}
    \item \textbf{scDataLoader}: \url{https://github.com/jkobject/scDataLoader}, DOI:\href{https://doi.org/10.5281/zenodo.10573143}{10.5281/zenodo.10573143}
    \item \textbf{scGPT and notebooks to reproduce the results}: \url{https://github.com/jkobject/scGPT/tree/main/mytests}
\end{itemize}

